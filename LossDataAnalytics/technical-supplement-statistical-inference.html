<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Loss Data Analytics</title>
  <meta name="description" content="Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Loss Data Analytics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Loss Data Analytics" />
  
  <meta name="twitter:description" content="Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  

<meta name="author" content="An open text authored by the Actuarial Community">


<meta name="date" content="2017-11-12">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="portfolio-management-including-reinsurance.html">
<link rel="next" href="bibliography.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
</script>
<script language="javascript">
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
</script>
<script language="javascript">
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
</script>
<script language="javascript">
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Loss Data Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html"><i class="fa fa-check"></i><b>1</b> Introduction to Loss Data Analytics</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#S:Intro"><i class="fa fa-check"></i><b>1.1</b> Relevance of Analytics</a><ul>
<li class="chapter" data-level="1.1.1" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#what-is-analytics"><i class="fa fa-check"></i><b>1.1.1</b> What is Analytics?</a></li>
<li class="chapter" data-level="1.1.2" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#short-term-insurance"><i class="fa fa-check"></i><b>1.1.2</b> Short-term Insurance</a></li>
<li class="chapter" data-level="1.1.3" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#S:InsProcesses"><i class="fa fa-check"></i><b>1.1.3</b> Insurance Processes</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#variable-types"><i class="fa fa-check"></i><b>1.2</b> Variable Types</a><ul>
<li class="chapter" data-level="1.2.1" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#qualitative-variables"><i class="fa fa-check"></i><b>1.2.1</b> Qualitative Variables</a></li>
<li class="chapter" data-level="1.2.2" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#quantitative-variables"><i class="fa fa-check"></i><b>1.2.2</b> Quantitative Variables</a></li>
<li class="chapter" data-level="1.2.3" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#multivariate-variables"><i class="fa fa-check"></i><b>1.2.3</b> Multivariate Variables</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#S:PredModApps"><i class="fa fa-check"></i><b>1.3</b> Insurance Company Operations</a><ul>
<li class="chapter" data-level="1.3.1" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#initiating-insurance"><i class="fa fa-check"></i><b>1.3.1</b> Initiating Insurance</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#renewing-insurance"><i class="fa fa-check"></i><b>1.3.2</b> Renewing Insurance</a></li>
<li class="chapter" data-level="1.3.3" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#claims-and-product-management"><i class="fa fa-check"></i><b>1.3.3</b> Claims and Product Management</a></li>
<li class="chapter" data-level="1.3.4" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#S:Reserving"><i class="fa fa-check"></i><b>1.3.4</b> Loss Reserving</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#S:LGPIF"><i class="fa fa-check"></i><b>1.4</b> Case Study: Wisconsin Property Fund</a><ul>
<li class="chapter" data-level="1.4.1" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#S:OutComes"><i class="fa fa-check"></i><b>1.4.1</b> Fund Claims Variables</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#S:FundVariables"><i class="fa fa-check"></i><b>1.4.2</b> Fund Rating Variables</a></li>
<li class="chapter" data-level="1.4.3" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#fund-operations"><i class="fa fa-check"></i><b>1.4.3</b> Fund Operations</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction-to-loss-data-analytics.html"><a href="introduction-to-loss-data-analytics.html#further-reading-and-resources"><i class="fa fa-check"></i><b>1.5</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="frequency-distributions.html"><a href="frequency-distributions.html"><i class="fa fa-check"></i><b>2</b> Frequency Distributions</a><ul>
<li class="chapter" data-level="2.1" data-path="frequency-distributions.html"><a href="frequency-distributions.html#how-frequency-augments-severity-information"><i class="fa fa-check"></i><b>2.1</b> How Frequency Augments Severity Information</a></li>
<li class="chapter" data-level="2.2" data-path="frequency-distributions.html"><a href="frequency-distributions.html#basic-frequency-distributions"><i class="fa fa-check"></i><b>2.2</b> Basic Frequency Distributions</a><ul>
<li class="chapter" data-level="2.2.1" data-path="frequency-distributions.html"><a href="frequency-distributions.html#foundations"><i class="fa fa-check"></i><b>2.2.1</b> Foundations</a></li>
<li class="chapter" data-level="2.2.2" data-path="frequency-distributions.html"><a href="frequency-distributions.html#probability-generating-function"><i class="fa fa-check"></i><b>2.2.2</b> Probability Generating Function</a></li>
<li class="chapter" data-level="2.2.3" data-path="frequency-distributions.html"><a href="frequency-distributions.html#important-frequency-distributions"><i class="fa fa-check"></i><b>2.2.3</b> Important Frequency Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="frequency-distributions.html"><a href="frequency-distributions.html#the-a-b-0-class"><i class="fa fa-check"></i><b>2.3</b> The (<span class="math inline">\(a, b\)</span>, 0) Class</a><ul>
<li class="chapter" data-level="2.3.1" data-path="frequency-distributions.html"><a href="frequency-distributions.html#the-a-b-0-class---example"><i class="fa fa-check"></i><b>2.3.1</b> The (<span class="math inline">\(a, b\)</span>, 0) Class - Example</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="frequency-distributions.html"><a href="frequency-distributions.html#estimating-frequency-distributions"><i class="fa fa-check"></i><b>2.4</b> Estimating Frequency Distributions</a></li>
<li class="chapter" data-level="2.5" data-path="frequency-distributions.html"><a href="frequency-distributions.html#other-frequency-distributions"><i class="fa fa-check"></i><b>2.5</b> Other Frequency Distributions</a><ul>
<li class="chapter" data-level="2.5.1" data-path="frequency-distributions.html"><a href="frequency-distributions.html#zero-truncation-or-modification"><i class="fa fa-check"></i><b>2.5.1</b> Zero Truncation or Modification</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="frequency-distributions.html"><a href="frequency-distributions.html#mixture-distributions"><i class="fa fa-check"></i><b>2.6</b> Mixture Distributions</a><ul>
<li class="chapter" data-level="2.6.1" data-path="frequency-distributions.html"><a href="frequency-distributions.html#mixtures-of-finite-populations"><i class="fa fa-check"></i><b>2.6.1</b> Mixtures of Finite Populations</a></li>
<li class="chapter" data-level="2.6.2" data-path="frequency-distributions.html"><a href="frequency-distributions.html#mixtures-of-infinitely-many-populations"><i class="fa fa-check"></i><b>2.6.2</b> Mixtures of Infinitely Many Populations</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="frequency-distributions.html"><a href="frequency-distributions.html#goodness-of-fit"><i class="fa fa-check"></i><b>2.7</b> Goodness of Fit</a></li>
<li class="chapter" data-level="2.8" data-path="frequency-distributions.html"><a href="frequency-distributions.html#exercises"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
<li class="chapter" data-level="2.9" data-path="frequency-distributions.html"><a href="frequency-distributions.html#technical-supplement-iterated-expectations"><i class="fa fa-check"></i><b>2.9</b> Technical Supplement: Iterated Expectations</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html"><i class="fa fa-check"></i><b>3</b> Modeling Loss Severity</a><ul>
<li class="chapter" data-level="3.1" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#BasicQuantities"><i class="fa fa-check"></i><b>3.1</b> Basic Distributional Quantities</a><ul>
<li class="chapter" data-level="3.1.1" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#moments"><i class="fa fa-check"></i><b>3.1.1</b> Moments</a></li>
<li class="chapter" data-level="3.1.2" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#quantiles"><i class="fa fa-check"></i><b>3.1.2</b> Quantiles</a></li>
<li class="chapter" data-level="3.1.3" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#the-moment-generating-function"><i class="fa fa-check"></i><b>3.1.3</b> The Moment Generating Function</a></li>
<li class="chapter" data-level="3.1.4" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#probability-generating-function-1"><i class="fa fa-check"></i><b>3.1.4</b> Probability Generating Function</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#ContinuousDistn"><i class="fa fa-check"></i><b>3.2</b> Continuous Distributions for Modeling Loss Severity</a><ul>
<li class="chapter" data-level="3.2.1" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#the-gamma-distribution"><i class="fa fa-check"></i><b>3.2.1</b> The Gamma Distribution</a></li>
<li class="chapter" data-level="3.2.2" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#the-pareto-distribution"><i class="fa fa-check"></i><b>3.2.2</b> The Pareto Distribution</a></li>
<li class="chapter" data-level="3.2.3" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#the-weibull-distribution"><i class="fa fa-check"></i><b>3.2.3</b> The Weibull Distribution</a></li>
<li class="chapter" data-level="3.2.4" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#the-generalized-beta-distribution-of-the-second-kind"><i class="fa fa-check"></i><b>3.2.4</b> The Generalized Beta Distribution of the Second Kind</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#MethodsCreation"><i class="fa fa-check"></i><b>3.3</b> Methods of Creating New Distributions</a><ul>
<li class="chapter" data-level="3.3.1" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#functions-of-random-variables-and-their-distributions"><i class="fa fa-check"></i><b>3.3.1</b> Functions of Random Variables and their Distributions</a></li>
<li class="chapter" data-level="3.3.2" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#multiplication-by-a-constant"><i class="fa fa-check"></i><b>3.3.2</b> Multiplication by a Constant</a></li>
<li class="chapter" data-level="3.3.3" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#raising-to-a-power"><i class="fa fa-check"></i><b>3.3.3</b> Raising to a Power</a></li>
<li class="chapter" data-level="3.3.4" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#exponentiation"><i class="fa fa-check"></i><b>3.3.4</b> Exponentiation</a></li>
<li class="chapter" data-level="3.3.5" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#finite-mixtures"><i class="fa fa-check"></i><b>3.3.5</b> Finite Mixtures</a></li>
<li class="chapter" data-level="3.3.6" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#continuous-mixtures"><i class="fa fa-check"></i><b>3.3.6</b> Continuous Mixtures</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#coverage-modifications"><i class="fa fa-check"></i><b>3.4</b> Coverage Modifications</a><ul>
<li class="chapter" data-level="3.4.1" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#PolicyDeduct"><i class="fa fa-check"></i><b>3.4.1</b> Policy Deductibles</a></li>
<li class="chapter" data-level="3.4.2" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#PolicyLimits"><i class="fa fa-check"></i><b>3.4.2</b> Policy Limits</a></li>
<li class="chapter" data-level="3.4.3" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#coinsurance"><i class="fa fa-check"></i><b>3.4.3</b> Coinsurance</a></li>
<li class="chapter" data-level="3.4.4" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#reinsurance"><i class="fa fa-check"></i><b>3.4.4</b> Reinsurance</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>3.5</b> Maximum Likelihood Estimation</a><ul>
<li class="chapter" data-level="3.5.1" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#maximum-likelihood-estimators-for-complete-data"><i class="fa fa-check"></i><b>3.5.1</b> Maximum Likelihood Estimators for Complete Data</a></li>
<li class="chapter" data-level="3.5.2" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#MLEGrouped"><i class="fa fa-check"></i><b>3.5.2</b> Maximum Likelihood Estimators for Grouped Data</a></li>
<li class="chapter" data-level="3.5.3" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#maximum-likelihood-estimators-for-censored-data"><i class="fa fa-check"></i><b>3.5.3</b> Maximum Likelihood Estimators for Censored Data</a></li>
<li class="chapter" data-level="3.5.4" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#maximum-likelihood-estimators-for-truncated-data"><i class="fa fa-check"></i><b>3.5.4</b> Maximum Likelihood Estimators for Truncated Data</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#Resources-loss-severity"><i class="fa fa-check"></i><b>3.6</b> Further Resources and Contributors</a></li>
<li class="chapter" data-level="3.7" data-path="modeling-loss-severity.html"><a href="modeling-loss-severity.html#exercises-1"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html"><i class="fa fa-check"></i><b>4</b> Model Selection, Validation, and Inference</a><ul>
<li class="chapter" data-level="4.1" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#S:NonParInf"><i class="fa fa-check"></i><b>4.1</b> Nonparametric Inference</a><ul>
<li class="chapter" data-level="4.1.1" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#nonparametric-estimation"><i class="fa fa-check"></i><b>4.1.1</b> Nonparametric Estimation</a></li>
<li class="chapter" data-level="4.1.2" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#S:ToolsModelSelection"><i class="fa fa-check"></i><b>4.1.2</b> Tools for Model Selection</a></li>
<li class="chapter" data-level="4.1.3" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#starting-values"><i class="fa fa-check"></i><b>4.1.3</b> Starting Values</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#S:ModelValidation"><i class="fa fa-check"></i><b>4.2</b> Model Validation</a><ul>
<li class="chapter" data-level="4.2.1" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#iterative-model-selection"><i class="fa fa-check"></i><b>4.2.1</b> Iterative Model Selection</a></li>
<li class="chapter" data-level="4.2.2" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#summarizing-model-selection"><i class="fa fa-check"></i><b>4.2.2</b> Summarizing Model Selection</a></li>
<li class="chapter" data-level="4.2.3" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#out-of-sample-validation"><i class="fa fa-check"></i><b>4.2.3</b> Out of Sample Validation</a></li>
<li class="chapter" data-level="4.2.4" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#gini-statistic"><i class="fa fa-check"></i><b>4.2.4</b> Gini Statistic</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#S:ModifiedData"><i class="fa fa-check"></i><b>4.3</b> Modified Data</a><ul>
<li class="chapter" data-level="4.3.1" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#parametric-estimation-using-modified-data"><i class="fa fa-check"></i><b>4.3.1</b> Parametric Estimation using Modified Data</a></li>
<li class="chapter" data-level="4.3.2" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#nonparametric-estimation-using-modified-data"><i class="fa fa-check"></i><b>4.3.2</b> Nonparametric Estimation using Modified Data</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#S:BayesInference"><i class="fa fa-check"></i><b>4.4</b> Bayesian Inference</a><ul>
<li class="chapter" data-level="4.4.1" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#bayesian-model"><i class="fa fa-check"></i><b>4.4.1</b> Bayesian Model</a></li>
<li class="chapter" data-level="4.4.2" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#decision-analysis"><i class="fa fa-check"></i><b>4.4.2</b> Decision Analysis</a></li>
<li class="chapter" data-level="4.4.3" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#posterior-distribution"><i class="fa fa-check"></i><b>4.4.3</b> Posterior Distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="model-selection-validation-and-inference.html"><a href="model-selection-validation-and-inference.html#exercises-2"><i class="fa fa-check"></i><b>4.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simulation.html"><a href="simulation.html"><i class="fa fa-check"></i><b>5</b> Simulation</a><ul>
<li class="chapter" data-level="5.1" data-path="simulation.html"><a href="simulation.html#generating-independent-uniform-observations"><i class="fa fa-check"></i><b>5.1</b> Generating Independent Uniform Observations</a></li>
<li class="chapter" data-level="5.2" data-path="simulation.html"><a href="simulation.html#inverse-transform"><i class="fa fa-check"></i><b>5.2</b> Inverse Transform</a></li>
<li class="chapter" data-level="5.3" data-path="simulation.html"><a href="simulation.html#how-many-simulated-values"><i class="fa fa-check"></i><b>5.3</b> How Many Simulated Values?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="portfolio-management-including-reinsurance.html"><a href="portfolio-management-including-reinsurance.html"><i class="fa fa-check"></i><b>6</b> Portfolio Management including Reinsurance</a><ul>
<li class="chapter" data-level="6.0.1" data-path="portfolio-management-including-reinsurance.html"><a href="portfolio-management-including-reinsurance.html#overview"><i class="fa fa-check"></i><b>6.0.1</b> Overview:</a></li>
<li class="chapter" data-level="6.1" data-path="portfolio-management-including-reinsurance.html"><a href="portfolio-management-including-reinsurance.html#tails-of-distributions"><i class="fa fa-check"></i><b>6.1</b> Tails of Distributions</a></li>
<li class="chapter" data-level="6.2" data-path="portfolio-management-including-reinsurance.html"><a href="portfolio-management-including-reinsurance.html#measures-of-risk"><i class="fa fa-check"></i><b>6.2</b> Measures of Risk</a></li>
<li class="chapter" data-level="6.3" data-path="portfolio-management-including-reinsurance.html"><a href="portfolio-management-including-reinsurance.html#reinsurance-1"><i class="fa fa-check"></i><b>6.3</b> Reinsurance</a><ul>
<li class="chapter" data-level="6.3.1" data-path="portfolio-management-including-reinsurance.html"><a href="portfolio-management-including-reinsurance.html#proportional-reinsurance"><i class="fa fa-check"></i><b>6.3.1</b> Proportional Reinsurance</a></li>
<li class="chapter" data-level="6.3.2" data-path="portfolio-management-including-reinsurance.html"><a href="portfolio-management-including-reinsurance.html#surplus-share-proportional-treaty"><i class="fa fa-check"></i><b>6.3.2</b> Surplus Share Proportional Treaty</a></li>
<li class="chapter" data-level="6.3.3" data-path="portfolio-management-including-reinsurance.html"><a href="portfolio-management-including-reinsurance.html#excess-of-loss-reinsurance"><i class="fa fa-check"></i><b>6.3.3</b> Excess of Loss Reinsurance</a></li>
<li class="chapter" data-level="6.3.4" data-path="portfolio-management-including-reinsurance.html"><a href="portfolio-management-including-reinsurance.html#relations-with-personal-insurance"><i class="fa fa-check"></i><b>6.3.4</b> Relations with Personal Insurance</a></li>
<li class="chapter" data-level="6.3.5" data-path="portfolio-management-including-reinsurance.html"><a href="portfolio-management-including-reinsurance.html#layers-of-coverage"><i class="fa fa-check"></i><b>6.3.5</b> Layers of Coverage</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="technical-supplement-statistical-inference.html"><a href="technical-supplement-statistical-inference.html"><i class="fa fa-check"></i><b>7</b> Technical Supplement: Statistical Inference</a><ul>
<li class="chapter" data-level="7.1" data-path="technical-supplement-statistical-inference.html"><a href="technical-supplement-statistical-inference.html#overview-of-statistical-inference"><i class="fa fa-check"></i><b>7.1</b> Overview of Statistical Inference</a></li>
<li class="chapter" data-level="7.2" data-path="technical-supplement-statistical-inference.html"><a href="technical-supplement-statistical-inference.html#estimation-and-prediction"><i class="fa fa-check"></i><b>7.2</b> Estimation and Prediction</a></li>
<li class="chapter" data-level="7.3" data-path="technical-supplement-statistical-inference.html"><a href="technical-supplement-statistical-inference.html#maximum-likelihood-theory"><i class="fa fa-check"></i><b>7.3</b> Maximum Likelihood Theory</a><ul>
<li class="chapter" data-level="7.3.1" data-path="technical-supplement-statistical-inference.html"><a href="technical-supplement-statistical-inference.html#likelihood-function"><i class="fa fa-check"></i><b>7.3.1</b> Likelihood Function</a></li>
<li class="chapter" data-level="7.3.2" data-path="technical-supplement-statistical-inference.html"><a href="technical-supplement-statistical-inference.html#information-criteria"><i class="fa fa-check"></i><b>7.3.2</b> Information Criteria</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Loss Data Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="technical-supplement-statistical-inference" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Technical Supplement: Statistical Inference</h1>
<div id="overview-of-statistical-inference" class="section level2">
<h2><span class="header-section-number">7.1</span> Overview of Statistical Inference</h2>
<ul>
<li><p>A set of data (a <strong>sample</strong>) has been collected that is considered representative of a larger set (the <strong>population</strong>). This relationship is known as the <strong>sampling frame</strong>.</p></li>
<li><p>Often, we can describe the distribution of the population in terms of a limited (finite) number of terms called <strong>parameters</strong>. These are referred to as <em>parametric distributions</em>. With <strong>nonparametric</strong> analysis, we do not limit ourselves to only a few parameters.</p></li>
<li><p>The <strong>statistical inference</strong> goal is to say something about the (larger) population based on the observed sample (we “<em>infer</em>,” not “<em>deduce</em>”). There are three types of statements:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Estimation</strong></p></li>
<li><p><strong>Hypothesis Testing</strong></p></li>
<li><p><strong>Prediction</strong></p></li>
</ol></li>
</ul>
<div id="wisconsin-property-fund" class="section level4">
<h4><span class="header-section-number">7.1.0.1</span> Wisconsin Property Fund</h4>
<ul>
<li><p>Discuss ideas of statistical inference in the context of a sample from the Wisconsin Property Fund</p></li>
<li><p>Specifically, consider 1,377 <em>individual</em> claims from 2010 experience (slightly different from the analysis of 403 average claims in Chapter 1)</p></li>
</ul>
<table>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td align="right">First</td>
<td></td>
<td></td>
<td align="right">Third</td>
<td></td>
<td align="right">Standard</td>
</tr>
<tr class="even">
<td></td>
<td>Minimum</td>
<td align="right">Quartile</td>
<td>Median</td>
<td>Mean</td>
<td align="right">Quartile</td>
<td>Maximum</td>
<td align="right">Deviation</td>
</tr>
<tr class="odd">
<td>Claims</td>
<td>1</td>
<td align="right">788</td>
<td>2,250</td>
<td>26,620</td>
<td align="right">6,171</td>
<td>12,920,000</td>
<td align="right">368,030</td>
</tr>
<tr class="even">
<td>Logarithmic Claims</td>
<td>0</td>
<td align="right">6.670</td>
<td>7.719</td>
<td>7.804</td>
<td align="right">8.728</td>
<td>16.370</td>
<td align="right">1.683</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ClaimLev &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;Data/CLAIMLEVEL.csv&quot;</span>, <span class="dt">header=</span><span class="ot">TRUE</span>)
ClaimLevBC10&lt;-<span class="kw">subset</span>(ClaimLev,Year==<span class="dv">2010</span>); <span class="kw">nrow</span>(ClaimLevBC10)</code></pre></div>
<pre><code>## [1] 1377</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))
<span class="kw">hist</span>(ClaimLevBC10$Claim, <span class="dt">main=</span><span class="st">&quot;&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;Claims&quot;</span>)
<span class="kw">hist</span>(<span class="kw">log</span>(ClaimLevBC10$Claim), <span class="dt">main=</span><span class="st">&quot;&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;Logarithmic Claims&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ClaimDistn1"></span>
<img src="LossDataAnalytics_files/figure-html/ClaimDistn1-1.png" alt="Distribution of Claims" width="80%" />
<p class="caption">
Figure 7.1: Distribution of Claims
</p>
</div>
</div>
<div id="sampling-frame" class="section level4">
<h4><span class="header-section-number">7.1.0.2</span> Sampling Frame</h4>
<ul>
<li><p>In statistics, a sampling frame <strong>error</strong> occurs when the sampling frame, the list from which the sample is drawn, is not an adequate approximation of the population of interest.</p></li>
<li><p>For the property fund example, the sample consists of all 2010 claims</p>
<ul>
<li><p>The population might be all claims that could have potentially occurred in 2010.</p></li>
<li><p>Or, it might be all claims that could potentially occur, such as in 2010, 2011, and so forth</p></li>
</ul></li>
<li><p>A sample must be a representative subset of a population, or “universe,” of interest. If the sample is not representative, taking a larger sample does not eliminate bias; you simply repeat the same mistake over again and again.</p></li>
<li><p>A sample should be a representative subset of a population, or “universe,” of interest.</p></li>
<li><p>Formally</p>
<ul>
<li><p>We assume that the random variable <span class="math inline">\(X\)</span> represents a draw from a population with distribution function F(.)</p></li>
<li><p>We make several such draws (<span class="math inline">\(n\)</span>), each unrelated to one another (statistically independent)</p></li>
<li><p>Sometimes we say that <span class="math inline">\(X_1, \ldots, X_n\)</span> is a random sample (with replacement) from F(.)</p></li>
<li><p>Sometimes we say that <span class="math inline">\(X_1, \ldots, X_n\)</span> are identically and independently distributed (<span class="math inline">\(iid\)</span>)</p></li>
</ul></li>
</ul>
</div>
<div id="describing-the-population" class="section level4">
<h4><span class="header-section-number">7.1.0.3</span> Describing the Population</h4>
<ul>
<li><p>We think of the random variable <span class="math inline">\(X\)</span> as a draw from the population with distribution function F(.)</p></li>
<li><p>There are several ways to summarize F(.). We might consider the mean, standard deviation, 95th percentile, and so on.</p>
<ul>
<li>Because these summary stats do not depend on a specific parametric reference, they are <strong>nonparametric</strong> summary measures.</li>
</ul></li>
<li><p>In contrast, we can think of logarithmic claims as normally distributed with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, that is, claims have a <em>lognormal</em> distribution</p></li>
<li><p>We will also look at the gamma distribution, with parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\theta\)</span>, as a claims model</p>
<ul>
<li><p>The normal, lognormal, and gamma are examples of <strong>parametric</strong> distributions.</p></li>
<li><p>The quantities <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>, <span class="math inline">\(\alpha\)</span>, and <span class="math inline">\(\theta\)</span> are known as <em>parameters</em>. When we know the parameters of a distribution family, then we have knowledge of the entire distribution.</p></li>
</ul></li>
</ul>
</div>
</div>
<div id="estimation-and-prediction" class="section level2">
<h2><span class="header-section-number">7.2</span> Estimation and Prediction</h2>
<div id="estimation" class="section level4">
<h4><span class="header-section-number">7.2.0.1</span> Estimation</h4>
<ul>
<li><p>Use <span class="math inline">\(\theta\)</span> to denote a summary of the population.</p>
<ul>
<li><p>Parametric - It can be a parameter from a distribution such as <span class="math inline">\(\mu\)</span> or <span class="math inline">\(\sigma\)</span>.</p></li>
<li><p>Nonparametric - It can also be a nonparametric summary such as the mean or standard deviation.</p></li>
</ul></li>
<li><p>Let <span class="math inline">\(\hat{\theta} =\hat{\theta}(X_1, \ldots, X_n)\)</span> be a function of the sample that provides proxy, or <strong>estimate</strong>, of <span class="math inline">\(\theta\)</span>. It is a function of the sample <span class="math inline">\(X_1, \ldots, X_n\)</span>.</p></li>
<li><p>In our property fund case,</p>
<ul>
<li><p>7.804 is a (nonparametric) estimate of the population expected logarithmic claim and 1.683 is an estimate of the corresponding standard deviation.</p></li>
<li><p>These are (parametric) estimates of the normal distribution for logarithmic claims</p></li>
<li><p>The estimate of the expected claim using the lognormal distribution is 10,106.8 (=<span class="math inline">\(\exp(7.804+1.683^2/2))\)</span>.</p></li>
</ul></li>
</ul>
</div>
<div id="lognormal-distribution-and-estimation" class="section level4">
<h4><span class="header-section-number">7.2.0.2</span> Lognormal Distribution and Estimation</h4>
<ul>
<li><p>Assume that claims follow a lognormal distribution, so that logarithmic claims follow the familiar normal distribution.</p></li>
<li><p>Specifically, assume <span class="math inline">\(\ln X\)</span> has a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, sometimes denoted as <span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>.</p></li>
<li><p>For the property data, estimates are <span class="math inline">\(\hat{\mu} =7.804\)</span> and <span class="math inline">\(\hat{\sigma} = 1.683\)</span>. The “hat” notation is common. These are said to be <strong>point estimates</strong>, a single approximation of the corresponding parameter.</p></li>
<li><p>Under general maximum likelihood theory (that we will do in a little bit), these estimates typically have a normal distribution for large samples.</p>
<ul>
<li><p>Using notation, <span class="math inline">\(\hat{\theta}\)</span> has an approximate normal distribution with mean <span class="math inline">\(\theta\)</span> and variance, say, <span class="math inline">\(\mathrm{Var}(\hat{\theta})\)</span>.</p></li>
<li><p>Take the square root of the variance and plug-in the estimate to define <span class="math inline">\(se(\hat{\theta}) = \sqrt{\mathrm{Var}(\hat{\theta})}\)</span>. A <strong>standard error</strong> is an estimated standard deviation.</p></li>
<li><p>The next step in the mathematical statistics theory is to establish that <span class="math inline">\((\hat{\theta}-\theta)/se(\hat{\theta})\)</span> has a <span class="math inline">\(t\)</span>-distribution with “degrees of freedom” (a parameter of the distribution) equal to the sample size minus the dimension of <span class="math inline">\(\theta\)</span>.</p></li>
</ul></li>
<li><p>Assume that claims follow a lognormal distribution, so that logarithmic claims follow the familiar normal distribution.</p></li>
<li><p>Under general maximum likelihood theory</p>
<ul>
<li><p><span class="math inline">\(\hat{\theta}\)</span> has an approximate normal distribution with mean <span class="math inline">\(\theta\)</span> and variance, say, <span class="math inline">\(\mathrm{Var}(\hat{\theta})\)</span>.</p></li>
<li><p>Take the square root of the variance and plug-in the estimate to define <span class="math inline">\(se(\hat{\theta}) = \sqrt{\mathrm{Var}(\hat{\theta})}\)</span>. A <strong>standard error</strong> is an estimated standard deviation.</p></li>
<li><p><span class="math inline">\((\hat{\theta}-\theta)/se(\hat{\theta})\)</span> has a <span class="math inline">\(t\)</span>-distribution with “degrees of freedom” (a parameter of the distribution) equal to the sample size minus the dimension of <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>As an application, we can invert this result to get a <strong>confidence interval</strong> for <span class="math inline">\(\theta\)</span>.</p></li>
</ul></li>
<li><p>A pair of statistics, <span class="math inline">\(\hat{\theta}_1\)</span> and <span class="math inline">\(\hat{\theta}_2\)</span>, provide an interval of the form <span class="math inline">\([\hat{\theta}_1, \hat{\theta}_2]\)</span> This interval is a <span class="math inline">\(1-\alpha\)</span> confidence interval for <span class="math inline">\(\theta\)</span> if <span class="math inline">\(\Pr\left(\hat{\theta}_1 \le \theta \le \hat{\theta}_2\right) \ge 1-\alpha.\)</span></p></li>
<li><p>For example, <span class="math inline">\(\hat{\theta}_1 = \hat{\mu} - (t-value) \hat{\sigma}/\sqrt{n}\)</span> and <span class="math inline">\(\hat{\theta}_2 = \hat{\mu} + (t-value) \hat{\sigma}/\sqrt{n}\)</span> provide a confidence interval for <span class="math inline">\(\theta=\mu\)</span>. When <span class="math inline">\(\alpha = 0.05\)</span>, <span class="math inline">\(t-value \approx 1.96\)</span>.</p></li>
<li><p>For the property fund, (7.715235, 7.893208) is a 95% confidence interval for <span class="math inline">\(\mu\)</span>.</p></li>
</ul>
</div>
<div id="lognormal-distribution-and-hypothesis-testing" class="section level4">
<h4><span class="header-section-number">7.2.0.3</span> Lognormal Distribution and Hypothesis Testing</h4>
<p>An important statistical inference procedure involves verifying ideas about parameters.</p>
<ul>
<li><p>To illustrate, in the property fund, assume that mean logarithmic claims have historically been approximately been <span class="math inline">\(\mu_0 = log(5000)= 8.517\)</span>. I might want to use 2010 data to see whether the mean of the distribution has changed. I also might want to test whether it has increased.</p></li>
<li><p>The actual 2010 average was <span class="math inline">\(\hat{\mu} =7.804\)</span>. Is this a significant departure from <span class="math inline">\(\mu_0 = 8.517\)</span>?</p></li>
<li><p>One way to think about it is in terms of standard errors. The deviation is <span class="math inline">\((8.517-7.804)/(1.683/\sqrt{1377}) = 15.72\)</span> standard errors. This is highly unlikely assuming an approximate normal distribution.</p></li>
<li><p>One hypothesis testing procedure begin with the calculation the test statistic <span class="math inline">\(t-stat=(\hat{\theta}-\theta_0)/se(\hat{\theta})\)</span>. Here, <span class="math inline">\(\theta_0\)</span> is an assumed value of the parameter.</p></li>
<li><p>Then, one rejects the hypothesized value if the test statistic <span class="math inline">\(t-stat\)</span> is “unusual.” To gauge “unusual,” use the same <span class="math inline">\(t\)</span>-distribution as introduced for confidence intervals.</p></li>
<li><p>If you only want to know about a difference, this is known as a “two-sided” test; use the same <span class="math inline">\(t-value\)</span> as the case for confidence intervals.</p></li>
<li><p>If you want to investigate whether there has been an increase (or decrease), then use a “one-sided” test.</p></li>
<li><p>Another useful concept in hypothesis testing is the <span class="math inline">\(p\)</span>-value, which is short hand for probability value. For a data set, a <span class="math inline">\(p\)</span>-value is defined to be the smallest significance level for which the null hypothesis would be rejected.</p></li>
</ul>
</div>
<div id="property-fund-other-distributions" class="section level4">
<h4><span class="header-section-number">7.2.0.4</span> Property Fund – Other Distributions</h4>
<ul>
<li><p>For numerical stability and extensions to regression applications, statistical packages often work with transformed version of parameters</p></li>
<li><p>The following estimates are from the <strong>R</strong> package <strong>VGAM</strong> (the function)</p></li>
</ul>
<table>
<tbody>
<tr class="odd">
<td align="left">Distribution</td>
<td align="right">Parameter</td>
<td align="right">Standard</td>
<td align="right"><span class="math inline">\(t\)</span>-stat</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="right">Estimate</td>
<td align="right">Error</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">Gamma</td>
<td align="right">10.190</td>
<td align="right">0.050</td>
<td align="right">203.831</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="right">-1.236</td>
<td align="right">0.030</td>
<td align="right">-41.180</td>
</tr>
<tr class="odd">
<td align="left">Lognormal</td>
<td align="right">7.804</td>
<td align="right">0.045</td>
<td align="right">172.089</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="right">0.520</td>
<td align="right">0.019</td>
<td align="right">27.303</td>
</tr>
<tr class="odd">
<td align="left">Pareto</td>
<td align="right">7.733</td>
<td align="right">0.093</td>
<td align="right">82.853</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="right">-0.001</td>
<td align="right">0.054</td>
<td align="right">-0.016</td>
</tr>
<tr class="odd">
<td align="left">GB2</td>
<td align="right">2.831</td>
<td align="right">1.000</td>
<td align="right">2.832</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="right">1.203</td>
<td align="right">0.292</td>
<td align="right">4.120</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="right">6.329</td>
<td align="right">0.390</td>
<td align="right">16.220</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="right">1.295</td>
<td align="right">0.219</td>
<td align="right">5.910</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="maximum-likelihood-theory" class="section level2">
<h2><span class="header-section-number">7.3</span> Maximum Likelihood Theory</h2>
<div id="likelihood-function" class="section level3">
<h3><span class="header-section-number">7.3.1</span> Likelihood Function</h3>
<ul>
<li><p>Let <span class="math inline">\(\mathrm{f}(\cdot;\boldsymbol\theta)\)</span> be the probability mass function if <span class="math inline">\(X\)</span> is discrete or the probability density function if it is continuous.</p></li>
<li><p>The likelihood is a function of the parameters (<span class="math inline">\(\boldsymbol \theta\)</span>) with the data (<span class="math inline">\(\mathbf{x}\)</span>) fixed rather than a function of the data with the parameters fixed.</p></li>
<li><p>Define the <em>log-likelihood function</em>, <span class="math display">\[L(\boldsymbol \theta) = L(\mathbf{x};\boldsymbol \theta ) = \ln \mathrm{f}(\mathbf{x};\boldsymbol \theta) = \sum_{i=1}^n \ln \mathrm{f}(x_i;\boldsymbol \theta),\]</span> evaluated at a realization <span class="math inline">\(\mathbf{x}\)</span>.</p></li>
<li><p>In the case of independence, the joint density function can be expressed as a product of the marginal density functions and, by taking logarithms, we can work with sums.</p></li>
</ul>
<div id="example.-pareto-distribution" class="section level4">
<h4><span class="header-section-number">7.3.1.1</span> Example. Pareto Distribution</h4>
<ul>
<li><p>Suppose that <span class="math inline">\(X_1, \ldots, X_n\)</span> represent a random sample from a single-parameter Pareto with cumulative distribution function: <span class="math display">\[\mathrm{F}(x) = 1- \left(\frac{500}{x}\right)^{\alpha}, ~~~~ x&gt;500 .\]</span></p></li>
<li><p>In this case, the single parameter is <span class="math inline">\(\theta = \alpha\)</span>.</p></li>
<li><p>The corresponding probability density function is <span class="math inline">\(\mathrm{f}(x) = 500^{\alpha} \alpha x^{-\alpha-1}\)</span> and the logarithmic likelihood is <span class="math display">\[L(\boldsymbol \alpha) = \sum_{i=1}^n \ln \mathrm{f}(x_i;\alpha) = n \alpha \ln 500 +n \ln \alpha -(\alpha+1)  \sum_{i=1}^n \ln x_i .\]</span></p></li>
</ul>
</div>
<div id="properties-of-likelihood-functions" class="section level4">
<h4><span class="header-section-number">7.3.1.2</span> Properties of Likelihood Functions</h4>
<ul>
<li><p>One basic property of likelihood functions is: <span class="math display">\[\label{E11:ScoreZero}
\mathrm{E} \left( \frac{ \partial}{\partial \boldsymbol \theta}
L(\boldsymbol \theta) \right) = \mathbf 0\]</span></p></li>
<li><p>The derivative of the log-likelihood function, <span class="math inline">\(\partial L(\boldsymbol \theta)/\partial \boldsymbol \theta\)</span>, is called the <em>score function</em>.</p></li>
<li><p>To see this, <span class="math display">\[\begin{aligned}
\mathrm{E} \left( \frac{ \partial}{\partial \boldsymbol \theta} L(\boldsymbol \theta) \right)
&amp;= \mathrm{E} \left( \frac{\frac{\partial}{\partial \boldsymbol \theta}\mathrm{f}(\mathbf{x};\boldsymbol \theta)}{\mathrm{f}(\mathbf{x};\boldsymbol \theta )}  \right)
= \int\frac{\partial}{\partial \boldsymbol \theta} \mathrm{f}(\mathbf{x};\boldsymbol \theta ) d \mathbf y \\
&amp;= \frac{\partial}{\partial \boldsymbol \theta} \int \mathrm{f}(\mathbf{x};\boldsymbol \theta ) d \mathbf y
= \frac{\partial}{\partial \boldsymbol \theta} 1 = \mathbf 0.\end{aligned}\]</span></p></li>
<li><p>Another basic property is: <span class="math display">\[
\mathrm{E} \left( \frac{ \partial^2}{\partial \boldsymbol \theta
\partial \boldsymbol \theta^{\prime}} L(\boldsymbol \theta) \right)
+ \mathrm{E} \left( \frac{ \partial L(\boldsymbol \theta)}{\partial
\boldsymbol \theta} \frac{ \partial L(\boldsymbol \theta)}{\partial
\boldsymbol \theta^{\prime}}
 \right) = \mathbf 0.\]</span></p></li>
<li><p>With this, we can define the <em>information matrix</em> <span class="math display">\[
\mathbf{I}(\boldsymbol \theta) = \mathrm{E} \left( \frac{ \partial
L(\boldsymbol \theta)}{\partial \boldsymbol \theta} \frac{ \partial
L(\boldsymbol \theta)}{\partial \boldsymbol \theta^{\prime}}
 \right) = -\mathrm{E} \left( \frac{ \partial^2}{\partial \boldsymbol \theta
\partial \boldsymbol \theta^{\prime}} L(\boldsymbol \theta) \right).\]</span></p></li>
<li><p>In general <span class="math display">\[\frac{ \partial}{\partial \boldsymbol \theta} L(\boldsymbol \theta)
=\frac{ \partial}{\partial \boldsymbol \theta} \ln \prod_{i=1}^n
\mathrm{f}(x_i;\boldsymbol \theta ) =\sum_{i=1}^n \frac{
\partial}{\partial \boldsymbol \theta}
\ln \mathrm{f}(x_i;\boldsymbol \theta ).\]</span> has a large sample <strong>normal distribution</strong> with mean <strong>0</strong> and variance <span class="math inline">\(\mathbf{I}(\boldsymbol \theta)\)</span>.</p></li>
</ul>
</div>
<div id="maximum-likelihood-estimators" class="section level4">
<h4><span class="header-section-number">7.3.1.3</span> Maximum Likelihood Estimators</h4>
<ul>
<li><p>The value of <span class="math inline">\(\boldsymbol \theta\)</span>, say <span class="math inline">\(\boldsymbol \theta_{MLE}\)</span>, that maximizes <span class="math inline">\(\mathrm{f}(\mathbf{x};\boldsymbol \theta)\)</span> is called the <em>maximum likelihood estimator</em>.</p></li>
<li><p>Maximum likelihood estimators are values of the parameters <span class="math inline">\(\boldsymbol \theta\)</span> that are “most likely” to have been produced by the data.</p></li>
<li><p>Because <span class="math inline">\(\ln(\cdot)\)</span> is a one-to-one function, we can also determine <span class="math inline">\(\boldsymbol \theta_{MLE}\)</span> by maximizing the log-likelihood function, <span class="math inline">\(L(\boldsymbol \theta)\)</span>.</p></li>
</ul>
<p><strong>Example. Course C/Exam 4. May 2000, 21.</strong> You are given the following five observations: 521, 658, 702, 819, 1217. You use the single-parameter Pareto with cumulative distribution function: <span class="math display">\[\mathrm{F}(x) = 1- \left(\frac{500}{x}\right)^{\alpha}, ~~~~ x&gt;500 .\]</span> Calculate the maximum likelihood estimate of the parameter <span class="math inline">\(\alpha\)</span>.</p>
</div>
<div id="instructor-notes" class="section level4">
<h4><span class="header-section-number">7.3.1.4</span> Instructor Notes</h4>
<p><strong>Example. Course C/Exam 4. May 2000, 21.</strong> You are given the following five observations: 521, 658, 702, 819, 1217. You use the single-parameter Pareto with cumulative distribution function: <span class="math display">\[\mathrm{F}(x) = 1- \left(\frac{500}{x}\right)^{\alpha}, ~~~~ x&gt;500 .\]</span> Calculate the maximum likelihood estimate of the parameter <span class="math inline">\(\alpha\)</span>.</p>
<p><em>Solution</em>. With <span class="math inline">\(n=5\)</span>, the logarithmic likelihood is <span class="math display">\[L(\alpha ) =  \sum_{i=1}^5 \ln \mathrm{f}(x_i;\alpha ) =  5 \alpha \ln 500 + 5 \ln \alpha
-(\alpha+1) \sum_{i=1}^5 \ln x_i.\]</span> Solving for the root of the score function yields <span class="math display">\[\frac{ \partial}{\partial \alpha } L(\alpha ) =    5  \ln 500 + 5 / \alpha -  \sum_{i=1}^5 \ln x_i
=_{set} 0 \Rightarrow \alpha_{MLE} = \frac{5}{\sum_{i=1}^5 \ln x_i - 5  \ln 500 } = 2.453 .\]</span></p>
</div>
<div id="asymptotic-normality-of-maximum-likelihood-estimators" class="section level4">
<h4><span class="header-section-number">7.3.1.5</span> Asymptotic Normality of Maximum Likelihood Estimators</h4>
<ul>
<li><p>Under broad conditions, <span class="math inline">\(\boldsymbol \theta_{MLE}\)</span> has a large sample normal distribution with mean <span class="math inline">\(\boldsymbol \theta\)</span> and variance <span class="math inline">\(\left( \mathbf{I}(\boldsymbol \theta) \right)^{-1}\)</span>.</p></li>
<li><p><span class="math inline">\(2 \left( L(\boldsymbol \theta_{MLE}) - L(\boldsymbol \theta) \right)\)</span> has a chi-square distribution with degrees of freedom equal to the dimension of <span class="math inline">\(\boldsymbol \theta\)</span> .</p></li>
<li><p>These are critical results upon which much of estimation and hypothesis testing is based.</p>
<p><strong>Example. Course C/Exam 4. Nov 2000, 13.</strong> A sample of ten observations comes from a parametric family <span class="math inline">\(f(x,; \theta_1, \theta_2)\)</span> with log-likelihood function <span class="math display">\[L(\theta_1, \theta_2)= \sum_{i=1}^{10} f(x_i; \theta_1, \theta_2) = -2.5 \theta_1^2 - 3
\theta_1 \theta_2 - \theta_2^2 + 5 \theta_1 + 2 \theta_2 + k,\]</span> where <span class="math inline">\(k\)</span> is a constant. Determine the estimated covariance matrix of the maximum likelihood estimator, <span class="math inline">\(\hat{\theta_1}, \hat{\theta_2}\)</span>.</p></li>
</ul>
</div>
<div id="instructor-notes-1" class="section level4">
<h4><span class="header-section-number">7.3.1.6</span> Instructor Notes</h4>
<p><strong>Example. Course C/Exam 4. Nov 2000, 13.</strong> A sample of ten observations comes from a parametric family <span class="math inline">\(f(x,; \theta_1, \theta_2)\)</span> with log-likelihood function <span class="math display">\[L(\theta_1, \theta_2)= \sum_{i=1}^{10} f(x_i; \theta_1, \theta_2) = -2.5 \theta_1^2 - 3
\theta_1 \theta_2 - \theta_2^2 + 5 \theta_1 + 2 \theta_2 + k,\]</span> where <span class="math inline">\(k\)</span> is a constant. Determine the estimated covariance matrix of the maximum likelihood estimator, <span class="math inline">\(\hat{\theta_1}, \hat{\theta_2}\)</span>.</p>
<p><em>Solution</em>. The matrix of second derivatives is <span class="math display">\[\left(
\begin{array}{cc}
  \frac{ \partial ^2}{\partial \theta_1 ^2 } L &amp; \frac{ \partial ^2}{\partial \theta_1 \partial \theta_2 } L  \\
  \frac{ \partial ^2}{\partial \theta_1 \partial \theta_2 } L &amp; \frac{ \partial ^2}{\partial \theta_1 ^2 } L
\end{array} \right) =
\left(
\begin{array}{cc}
  -5 &amp; -3  \\
  -3 &amp; -2
\end{array} \right)\]</span> Thus, the information matrix is: <span class="math display">\[\mathbf{I}(\theta_1, \theta_2) = -\mathrm{E} \left( \frac{ \partial^2}{\partial \boldsymbol \theta
\partial \boldsymbol \theta^{\prime}} L(\boldsymbol \theta) \right) = \left(
\begin{array}{cc}
  5 &amp; 3  \\
  3 &amp; 2
\end{array} \right)\]</span> and <span class="math display">\[\mathbf{I}^{-1}(\theta_1, \theta_2) = \frac{1}{5(2) - 3(3)}\left(
\begin{array}{cc}
  2 &amp; -3  \\
  -3 &amp; 5
\end{array} \right) = \left(
\begin{array}{cc}
  2 &amp; -3  \\
  -3 &amp; 5
\end{array} \right) .\]</span></p>
</div>
<div id="maximum-likelihood-estimation-mle" class="section level4">
<h4><span class="header-section-number">7.3.1.7</span> Maximum Likelihood Estimation (MLE)</h4>
<ul>
<li><p>Why use maximum likelihood estimation?</p>
<ul>
<li><p>General purpose tool - works in many situations (data can be censored, truncated, include covariates, time-dependent, and so forth)</p></li>
<li><p>It is “optimal,” the best, in the sense that it has the smallest variance among the class of all unbiased estimators. (Caveat: for large sample sizes).</p></li>
</ul></li>
<li><p>A drawback: Generally, maximum likelihood estimators are computed iteratively, no closed-form solution.</p>
<ul>
<li><p>For example, you may recall a “Newton-Raphson” iterative algorithm from calculus</p></li>
<li><p>Iterative algorithms require starting values. For some problems, the choice of a close starting value is critical.</p></li>
</ul></li>
</ul>
</div>
<div id="mle-and-statistical-significance" class="section level4">
<h4><span class="header-section-number">7.3.1.8</span> MLE and Statistical Significance</h4>
<p>One important type inference is to say whether a parameter estimate is “statistically significant”</p>
<ul>
<li><p>We learned earlier that <span class="math inline">\(\boldsymbol \theta_{MLE}\)</span> has a large sample normal distribution with mean <span class="math inline">\(\boldsymbol \theta\)</span> and variance <span class="math inline">\(\left( \mathbf{I}(\boldsymbol \theta) \right)^{-1}\)</span>.</p></li>
<li><p>Look to the <span class="math inline">\(j\)</span>th element of <span class="math inline">\(\boldsymbol \theta_{MLE}\)</span>, say <span class="math inline">\(\theta_{MLE,j}\)</span>.</p></li>
<li><p>Define <span class="math inline">\(se(\theta_{MLE,j})\)</span>, the standard error (estimated standard deviation) to be square root of the <span class="math inline">\(j\)</span> diagonal element of <span class="math inline">\(\left( \mathbf{I}(\boldsymbol \theta)_{MLE} \right)^{-1}\)</span>.</p></li>
<li><p>To assess the hypothesis that <span class="math inline">\(\theta_j\)</span> is 0, we look at the rescaled estimate <span class="math inline">\(t(\theta_{MLE,j})=\theta_{MLE,j}/se(\theta_{MLE,j})\)</span>. It is said to be a <span class="math inline">\(t\)</span>-statistic or <span class="math inline">\(t\)</span>-ratio.</p></li>
<li><p>Under this hypothesis, it has a <span class="math inline">\(t\)</span>-distribution with degrees of freedom equal to the sample size minus the dimension of <span class="math inline">\(\boldsymbol \theta_{MLE}\)</span>.</p></li>
<li><p>For most actuarial applications, the <span class="math inline">\(t\)</span>-distribution is very close to the (standard) normal distribution. Thus, sometimes this ratio is also known a <span class="math inline">\(z\)</span>-statistic or “<span class="math inline">\(z\)</span>-score.”</p></li>
</ul>
</div>
<div id="assessing-statistical-significance" class="section level4">
<h4><span class="header-section-number">7.3.1.9</span> Assessing Statistical Significance</h4>
<ul>
<li><p>If the <span class="math inline">\(t\)</span>-statistic <span class="math inline">\(t(\theta_{MLE,j})\)</span> exceeds a cut-off (in absolute value), then the <span class="math inline">\(j\)</span>th variable is said to be “statistically significant.”</p>
<ul>
<li><p>For example, if we use a 5% significance level, then the cut-off is 1.96 using a normal distribution approximation.</p></li>
<li><p>More generally, using a <span class="math inline">\(100 \alpha \%\)</span> significance level, then the cut-off is a <span class="math inline">\(100(1-\alpha/2)\%\)</span> quantile from a <span class="math inline">\(t\)</span>-distribution using degrees of freedom equal to the sample size minus the dimension of <span class="math inline">\(\boldsymbol \theta_{MLE}\)</span>.</p></li>
</ul></li>
<li><p>Another useful concept in hypothesis testing is the <span class="math inline">\(p\)</span>-value, shorthand for probability value.</p>
<ul>
<li><p>For a data set, a <span class="math inline">\(p\)</span>-value is defined as the smallest significance level for which the null hypothesis would be rejected.</p></li>
<li><p>The <span class="math inline">\(p\)</span>-value is a useful summary statistic for the data analyst to report because it allows the reader to understand the strength of the deviation from the null hypothesis.</p></li>
</ul></li>
</ul>
</div>
<div id="mle-and-model-validation" class="section level4">
<h4><span class="header-section-number">7.3.1.10</span> MLE and Model Validation</h4>
<p>Another important type inference is to select a model from two choices, where one choice is a subset of the other</p>
<ul>
<li><p>Suppose that we have a (large) model and determine the maximum likelihood estimator, <span class="math inline">\(\boldsymbol \theta_{MLE}\)</span>.</p></li>
<li><p>Now assume that <span class="math inline">\(p\)</span> elements in <span class="math inline">\(\boldsymbol \theta\)</span> are equal to zero and determine the maximum likelihood estimator over the remaining set. Call this estimator <span class="math inline">\(\boldsymbol \theta_{Reduced}\)</span></p></li>
<li><p>The statistic, <span class="math inline">\(LRT= 2 \left( L(\boldsymbol \theta_{MLE}) - L(\boldsymbol \theta_{Reduced}) \right)\)</span>, is called the likelihood ratio (a difference of the logs is the log of the ratio. Hence, the term “ratio.”)</p></li>
<li><p>Under the hypothesis that the reduce model is correct, the likelihood ratio has a chi-square distribution with degrees of freedom equal to <span class="math inline">\(p\)</span>, the number of variables set equal to zero.</p></li>
<li><p>This allows us to judge which of the two models is correct. If the statistic <span class="math inline">\(LRT\)</span> is large relative to the chi-square distribution, then we reject the simpler, reduced, model in favor of the larger one.</p></li>
</ul>
</div>
</div>
<div id="information-criteria" class="section level3">
<h3><span class="header-section-number">7.3.2</span> Information Criteria</h3>
<ul>
<li><p>These statistics can be used when comparing several alternative models that are not necessarily nested. One picks the model that minimizes the criterion.</p></li>
<li><p><em>Akaike’s Information Criterion</em> <span class="math display">\[AIC = -2 \times L(\boldsymbol \theta_{MLE}) + 2 \times (number~of~parameters)\]</span></p>
<ul>
<li><p>The additional term <span class="math inline">\(2 \times \text{(number of parameters)}\)</span> is a penalty for the complexity of the model.</p></li>
<li><p>Other things equal, a more complex model means more parameters, resulting in a larger value of the criterion.</p></li>
</ul></li>
<li><p><em>Bayesian Information Criterion</em>, defined as <span class="math display">\[BIC = -2 \times L(\boldsymbol \theta_{MLE}) + (number~of~parameters) \times \ln (number~of~observations)\]</span></p>
<ul>
<li><p>This measure gives greater weight to the number of parameters.</p></li>
<li><p>Other things being equal, <span class="math inline">\(BIC\)</span> will suggest a more parsimonious model than <span class="math inline">\(AIC\)</span>.</p></li>
</ul></li>
</ul>
<div id="property-fund-information-criteria" class="section level4">
<h4><span class="header-section-number">7.3.2.1</span> Property Fund Information Criteria</h4>
<ul>
<li>Both the <span class="math inline">\(AIC\)</span> and <span class="math inline">\(BIC\)</span> statistics suggest that the <em>GB2</em> is the best fitting model whereas gamma is the worst.</li>
</ul>
<table>
<thead>
<tr class="header">
<th align="left">Distribution</th>
<th align="right">AIC</th>
<th align="right">BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Gamma</td>
<td align="right">28,305.2</td>
<td align="right">28,315.6</td>
</tr>
<tr class="even">
<td align="left">Lognormal</td>
<td align="right">26,837.7</td>
<td align="right">26,848.2</td>
</tr>
<tr class="odd">
<td align="left">Pareto</td>
<td align="right">26,813.3</td>
<td align="right">26,823.7</td>
</tr>
<tr class="even">
<td align="left">GB2</td>
<td align="right">26,768.1</td>
<td align="right">26,789.0</td>
</tr>
</tbody>
</table>
</div>
<div id="property-fund-fitted-distributions" class="section level4">
<h4><span class="header-section-number">7.3.2.2</span> Property Fund Fitted Distributions</h4>
<ul>
<li><p>In this graph, black represents actual (smoothed) logarithmic claims</p></li>
<li><p>Best approximated by green which is fitted GB2</p></li>
<li><p>Pareto (purple) and Lognormal (lightblue) are also pretty good</p></li>
<li><p>Worst are the exponential (in red) and gamma (in dark blue)</p></li>
</ul>
<pre><code>## [1] 6258</code></pre>
<div class="figure" style="text-align: center"><span id="fig:FitClaimDistn"></span>
<img src="LossDataAnalytics_files/figure-html/FitClaimDistn-1.png" alt="Fitted Claims Distribution" width="80%" />
<p class="caption">
Figure 7.2: Fitted Claims Distribution
</p>
</div>
<h5 style="text-align: center;">
<a id="display.FitClaimDistn.1" href="javascript:togglecode('display.FitClaimDistn.2','display.FitClaimDistn.1');"><i><strong>R Code for Fitted Claims Distributions</strong></i></a>
</h5>
<div id="display.FitClaimDistn.2" style="display: none">
<pre><code># R Code to fit several claims distributions
ClaimLev &lt;- read.csv(&quot;Data/CLAIMLEVEL.csv&quot;, header=TRUE); nrow(ClaimLev)
ClaimData&lt;-subset(ClaimLev,Year==2010); 
#Use &quot;VGAM&quot; library for estimation of parameters 
library(VGAM)
fit.LN &lt;- vglm(Claim ~ 1, family=lognormal, data = ClaimData)
fit.gamma &lt;- vglm(Claim ~ 1, family=gamma2, data = ClaimData)
  theta.gamma&lt;-exp(coef(fit.gamma)[1])/exp(coef(fit.gamma)[2]) 
  alpha.gamma&lt;-exp(coef(fit.gamma)[2])
fit.exp &lt;- vglm(Claim ~ 1, exponential, data = ClaimData)
fit.pareto &lt;- vglm(Claim ~ 1, paretoII, loc=0, data = ClaimData)

###################################################
#  Inference assuming a GB2 Distribution - this is more complicated
# The likelihood functon of GB2 distribution (negative for optimization)
likgb2 &lt;- function(param) {
  a1 &lt;- param[1]
  a2 &lt;- param[2]
  mu &lt;- param[3]
  sigma &lt;- param[4]
  yt &lt;- (log(ClaimData$Claim)-mu)/sigma
  logexpyt&lt;-ifelse(yt&gt;23,yt,log(1+exp(yt)))
  logdens &lt;- a1*yt - log(sigma) - log(beta(a1,a2)) - (a1+a2)*logexpyt -log(ClaimData$Claim) 
  return(-sum(logdens))
}
#  &quot;optim&quot; is a general purpose minimization function
gb2bop &lt;- optim(c(1,1,0,1),likgb2,method=c(&quot;L-BFGS-B&quot;),
                lower=c(0.01,0.01,-500,0.01),upper=c(500,500,500,500),hessian=TRUE)
###################################################
# Plotting the fit using densities (on a logarithmic scale)
plot(density(log(ClaimData$Claim)), ylim=c(0,0.36),main=&quot;&quot;, xlab=&quot;Log Expenditures&quot;)
x &lt;- seq(0,15,by=0.01)
fexp_ex = dgamma(exp(x), scale = exp(-coef(fit.exp)), shape = 1)*exp(x)
lines(x,fexp_ex, col=&quot;red&quot;)
fgamma_ex = dgamma(exp(x), shape = alpha.gamma, scale=theta.gamma)*exp(x)
lines(x,fgamma_ex,col=&quot;blue&quot;)
fpareto_ex = dparetoII(exp(x),loc=0,shape = exp(coef(fit.pareto)[2]), scale = exp(coef(fit.pareto)[1]))*exp(x)
lines(x,fpareto_ex,col=&quot;purple&quot;)
flnorm_ex = dlnorm(exp(x), mean = coef(fit.LN)[1], sd = exp(coef(fit.LN)[2]))*exp(x)
lines(x,flnorm_ex, col=&quot;lightblue&quot;)
# density for GB II
gb2density &lt;- function(x){
  a1 &lt;- gb2bop$par[1]
  a2 &lt;- gb2bop$par[2]
  mu &lt;- gb2bop$par[3]
  sigma &lt;- gb2bop$par[4]
  xt &lt;- (log(x)-mu)/sigma
  logexpxt&lt;-ifelse(xt&gt;23,yt,log(1+exp(xt)))
  logdens &lt;- a1*xt - log(sigma) - log(beta(a1,a2)) - (a1+a2)*logexpxt -log(x) 
  exp(logdens)
}
fGB2_ex = gb2density(exp(x))*exp(x)
lines(x,fGB2_ex, col=&quot;green&quot;)</code></pre>
</div>

</div>
</div>
</div>
</div>
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//lossdataanalytics.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="portfolio-management-including-reinsurance.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bibliography.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/Chapters/TexSuppStatisticalInference_16Dec2016Jan19.Rmd",
"text": "Edit"
},
"download": ["LossDataAnalytics.pdf", "LossDataAnalytics.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
