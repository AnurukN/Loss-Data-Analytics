<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Loss Data Analytics</title>
  <meta name="description" content="Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Loss Data Analytics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  <meta name="github-repo" content="<a href="https://github.com/ewfrees/Loss-Data-Analytics" class="uri">https://github.com/ewfrees/Loss-Data-Analytics</a>" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Loss Data Analytics" />
  
  <meta name="twitter:description" content="Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  

<meta name="author" content="An open text authored by the Actuarial Community">


<meta name="date" content="2018-05-19">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="C-Intro.html">
<link rel="next" href="C-Severity.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
</script>
<script language="javascript">
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
</script>
<script language="javascript">
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
</script>
<script language="javascript">
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Loss Data Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="contributor-list.html"><a href="contributor-list.html"><i class="fa fa-check"></i>Contributor List</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a><ul>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html#reviewer-acknowledgment"><i class="fa fa-check"></i>Reviewer Acknowledgment</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="C-Intro.html"><a href="C-Intro.html"><i class="fa fa-check"></i><b>1</b> Introduction to Loss Data Analytics</a><ul>
<li class="chapter" data-level="1.1" data-path="C-Intro.html"><a href="C-Intro.html#S:Intro"><i class="fa fa-check"></i><b>1.1</b> Relevance of Analytics</a><ul>
<li class="chapter" data-level="1.1.1" data-path="C-Intro.html"><a href="C-Intro.html#what-is-analytics"><i class="fa fa-check"></i><b>1.1.1</b> What is Analytics?</a></li>
<li class="chapter" data-level="1.1.2" data-path="C-Intro.html"><a href="C-Intro.html#short-term-insurance"><i class="fa fa-check"></i><b>1.1.2</b> Short-term Insurance</a></li>
<li class="chapter" data-level="1.1.3" data-path="C-Intro.html"><a href="C-Intro.html#S:InsProcesses"><i class="fa fa-check"></i><b>1.1.3</b> Insurance Processes</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="C-Intro.html"><a href="C-Intro.html#S:PredModApps"><i class="fa fa-check"></i><b>1.2</b> Insurance Company Operations</a><ul>
<li class="chapter" data-level="1.2.1" data-path="C-Intro.html"><a href="C-Intro.html#initiating-insurance"><i class="fa fa-check"></i><b>1.2.1</b> Initiating Insurance</a></li>
<li class="chapter" data-level="1.2.2" data-path="C-Intro.html"><a href="C-Intro.html#renewing-insurance"><i class="fa fa-check"></i><b>1.2.2</b> Renewing Insurance</a></li>
<li class="chapter" data-level="1.2.3" data-path="C-Intro.html"><a href="C-Intro.html#claims-and-product-management"><i class="fa fa-check"></i><b>1.2.3</b> Claims and Product Management</a></li>
<li class="chapter" data-level="1.2.4" data-path="C-Intro.html"><a href="C-Intro.html#S:Reserving"><i class="fa fa-check"></i><b>1.2.4</b> Loss Reserving</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="C-Intro.html"><a href="C-Intro.html#S:LGPIF"><i class="fa fa-check"></i><b>1.3</b> Case Study: Wisconsin Property Fund</a><ul>
<li class="chapter" data-level="1.3.1" data-path="C-Intro.html"><a href="C-Intro.html#S:OutComes"><i class="fa fa-check"></i><b>1.3.1</b> Fund Claims Variables</a></li>
<li class="chapter" data-level="1.3.2" data-path="C-Intro.html"><a href="C-Intro.html#S:FundVariables"><i class="fa fa-check"></i><b>1.3.2</b> Fund Rating Variables</a></li>
<li class="chapter" data-level="1.3.3" data-path="C-Intro.html"><a href="C-Intro.html#fund-operations"><i class="fa fa-check"></i><b>1.3.3</b> Fund Operations</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="C-Intro.html"><a href="C-Intro.html#further-reading-and-resources"><i class="fa fa-check"></i><b>1.4</b> Contributors and Further Resources</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="C-Frequency.html"><a href="C-Frequency.html"><i class="fa fa-check"></i><b>2</b> Frequency Distributions</a><ul>
<li class="chapter" data-level="2.1" data-path="C-Frequency.html"><a href="C-Frequency.html#how-frequency-augments-severity-information"><i class="fa fa-check"></i><b>2.1</b> How Frequency Augments Severity Information</a></li>
<li class="chapter" data-level="2.2" data-path="C-Frequency.html"><a href="C-Frequency.html#basic-frequency-distributions"><i class="fa fa-check"></i><b>2.2</b> Basic Frequency Distributions</a><ul>
<li class="chapter" data-level="2.2.1" data-path="C-Frequency.html"><a href="C-Frequency.html#foundations"><i class="fa fa-check"></i><b>2.2.1</b> Foundations</a></li>
<li class="chapter" data-level="2.2.2" data-path="C-Frequency.html"><a href="C-Frequency.html#probability-generating-function"><i class="fa fa-check"></i><b>2.2.2</b> Probability Generating Function</a></li>
<li class="chapter" data-level="2.2.3" data-path="C-Frequency.html"><a href="C-Frequency.html#important-frequency-distributions"><i class="fa fa-check"></i><b>2.2.3</b> Important Frequency Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="C-Frequency.html"><a href="C-Frequency.html#the-a-b-0-class"><i class="fa fa-check"></i><b>2.3</b> The (a, b, 0) Class</a><ul>
<li class="chapter" data-level="2.3.1" data-path="C-Frequency.html"><a href="C-Frequency.html#the-a-b-0-class---example"><i class="fa fa-check"></i><b>2.3.1</b> The (a, b, 0) Class - Example</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="C-Frequency.html"><a href="C-Frequency.html#estimating-frequency-distributions"><i class="fa fa-check"></i><b>2.4</b> Estimating Frequency Distributions</a></li>
<li class="chapter" data-level="2.5" data-path="C-Frequency.html"><a href="C-Frequency.html#other-frequency-distributions"><i class="fa fa-check"></i><b>2.5</b> Other Frequency Distributions</a><ul>
<li class="chapter" data-level="2.5.1" data-path="C-Frequency.html"><a href="C-Frequency.html#zero-truncation-or-modification"><i class="fa fa-check"></i><b>2.5.1</b> Zero Truncation or Modification</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="C-Frequency.html"><a href="C-Frequency.html#mixture-distributions"><i class="fa fa-check"></i><b>2.6</b> Mixture Distributions</a><ul>
<li class="chapter" data-level="2.6.1" data-path="C-Frequency.html"><a href="C-Frequency.html#mixtures-of-finite-populations"><i class="fa fa-check"></i><b>2.6.1</b> Mixtures of Finite Populations</a></li>
<li class="chapter" data-level="2.6.2" data-path="C-Frequency.html"><a href="C-Frequency.html#mixtures-of-infinitely-many-populations"><i class="fa fa-check"></i><b>2.6.2</b> Mixtures of Infinitely Many Populations</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="C-Frequency.html"><a href="C-Frequency.html#goodness-of-fit"><i class="fa fa-check"></i><b>2.7</b> Goodness of Fit</a></li>
<li class="chapter" data-level="2.8" data-path="C-Frequency.html"><a href="C-Frequency.html#exercises"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="C-Severity.html"><a href="C-Severity.html"><i class="fa fa-check"></i><b>3</b> Modeling Loss Severity</a><ul>
<li class="chapter" data-level="3.1" data-path="C-Severity.html"><a href="C-Severity.html#BasicQuantities"><i class="fa fa-check"></i><b>3.1</b> Basic Distributional Quantities</a><ul>
<li class="chapter" data-level="3.1.1" data-path="C-Severity.html"><a href="C-Severity.html#moments"><i class="fa fa-check"></i><b>3.1.1</b> Moments</a></li>
<li class="chapter" data-level="3.1.2" data-path="C-Severity.html"><a href="C-Severity.html#quantiles"><i class="fa fa-check"></i><b>3.1.2</b> Quantiles</a></li>
<li class="chapter" data-level="3.1.3" data-path="C-Severity.html"><a href="C-Severity.html#the-moment-generating-function"><i class="fa fa-check"></i><b>3.1.3</b> The Moment Generating Function</a></li>
<li class="chapter" data-level="3.1.4" data-path="C-Severity.html"><a href="C-Severity.html#probability-generating-function-1"><i class="fa fa-check"></i><b>3.1.4</b> Probability Generating Function</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="C-Severity.html"><a href="C-Severity.html#ContinuousDistn"><i class="fa fa-check"></i><b>3.2</b> Continuous Distributions for Modeling Loss Severity</a><ul>
<li class="chapter" data-level="3.2.1" data-path="C-Severity.html"><a href="C-Severity.html#the-gamma-distribution"><i class="fa fa-check"></i><b>3.2.1</b> The Gamma Distribution</a></li>
<li class="chapter" data-level="3.2.2" data-path="C-Severity.html"><a href="C-Severity.html#the-pareto-distribution"><i class="fa fa-check"></i><b>3.2.2</b> The Pareto Distribution</a></li>
<li class="chapter" data-level="3.2.3" data-path="C-Severity.html"><a href="C-Severity.html#the-weibull-distribution"><i class="fa fa-check"></i><b>3.2.3</b> The Weibull Distribution</a></li>
<li class="chapter" data-level="3.2.4" data-path="C-Severity.html"><a href="C-Severity.html#the-generalized-beta-distribution-of-the-second-kind"><i class="fa fa-check"></i><b>3.2.4</b> The Generalized Beta Distribution of the Second Kind</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="C-Severity.html"><a href="C-Severity.html#MethodsCreation"><i class="fa fa-check"></i><b>3.3</b> Methods of Creating New Distributions</a><ul>
<li class="chapter" data-level="3.3.1" data-path="C-Severity.html"><a href="C-Severity.html#functions-of-random-variables-and-their-distributions"><i class="fa fa-check"></i><b>3.3.1</b> Functions of Random Variables and their Distributions</a></li>
<li class="chapter" data-level="3.3.2" data-path="C-Severity.html"><a href="C-Severity.html#multiplication-by-a-constant"><i class="fa fa-check"></i><b>3.3.2</b> Multiplication by a Constant</a></li>
<li class="chapter" data-level="3.3.3" data-path="C-Severity.html"><a href="C-Severity.html#raising-to-a-power"><i class="fa fa-check"></i><b>3.3.3</b> Raising to a Power</a></li>
<li class="chapter" data-level="3.3.4" data-path="C-Severity.html"><a href="C-Severity.html#exponentiation"><i class="fa fa-check"></i><b>3.3.4</b> Exponentiation</a></li>
<li class="chapter" data-level="3.3.5" data-path="C-Severity.html"><a href="C-Severity.html#finite-mixtures"><i class="fa fa-check"></i><b>3.3.5</b> Finite Mixtures</a></li>
<li class="chapter" data-level="3.3.6" data-path="C-Severity.html"><a href="C-Severity.html#continuous-mixtures"><i class="fa fa-check"></i><b>3.3.6</b> Continuous Mixtures</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="C-Severity.html"><a href="C-Severity.html#coverage-modifications"><i class="fa fa-check"></i><b>3.4</b> Coverage Modifications</a><ul>
<li class="chapter" data-level="3.4.1" data-path="C-Severity.html"><a href="C-Severity.html#PolicyDeduct"><i class="fa fa-check"></i><b>3.4.1</b> Policy Deductibles</a></li>
<li class="chapter" data-level="3.4.2" data-path="C-Severity.html"><a href="C-Severity.html#PolicyLimits"><i class="fa fa-check"></i><b>3.4.2</b> Policy Limits</a></li>
<li class="chapter" data-level="3.4.3" data-path="C-Severity.html"><a href="C-Severity.html#coinsurance"><i class="fa fa-check"></i><b>3.4.3</b> Coinsurance</a></li>
<li class="chapter" data-level="3.4.4" data-path="C-Severity.html"><a href="C-Severity.html#reinsurance"><i class="fa fa-check"></i><b>3.4.4</b> Reinsurance</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="C-Severity.html"><a href="C-Severity.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>3.5</b> Maximum Likelihood Estimation</a><ul>
<li class="chapter" data-level="3.5.1" data-path="C-Severity.html"><a href="C-Severity.html#maximum-likelihood-estimators-for-complete-data"><i class="fa fa-check"></i><b>3.5.1</b> Maximum Likelihood Estimators for Complete Data</a></li>
<li class="chapter" data-level="3.5.2" data-path="C-Severity.html"><a href="C-Severity.html#MLEGrouped"><i class="fa fa-check"></i><b>3.5.2</b> Maximum Likelihood Estimators for Grouped Data</a></li>
<li class="chapter" data-level="3.5.3" data-path="C-Severity.html"><a href="C-Severity.html#maximum-likelihood-estimators-for-censored-data"><i class="fa fa-check"></i><b>3.5.3</b> Maximum Likelihood Estimators for Censored Data</a></li>
<li class="chapter" data-level="3.5.4" data-path="C-Severity.html"><a href="C-Severity.html#maximum-likelihood-estimators-for-truncated-data"><i class="fa fa-check"></i><b>3.5.4</b> Maximum Likelihood Estimators for Truncated Data</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="C-Severity.html"><a href="C-Severity.html#Resources-loss-severity"><i class="fa fa-check"></i><b>3.6</b> Further Resources and Contributors</a></li>
<li class="chapter" data-level="3.7" data-path="C-Severity.html"><a href="C-Severity.html#exercises-1"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html"><i class="fa fa-check"></i><b>4</b> Model Selection, Validation, and Inference</a><ul>
<li class="chapter" data-level="4.1" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:NonParInf"><i class="fa fa-check"></i><b>4.1</b> Nonparametric Inference</a><ul>
<li class="chapter" data-level="4.1.1" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#nonparametric-estimation"><i class="fa fa-check"></i><b>4.1.1</b> Nonparametric Estimation</a></li>
<li class="chapter" data-level="4.1.2" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:ToolsModelSelection"><i class="fa fa-check"></i><b>4.1.2</b> Tools for Model Selection</a></li>
<li class="chapter" data-level="4.1.3" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#starting-values"><i class="fa fa-check"></i><b>4.1.3</b> Starting Values</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:ModelValidation"><i class="fa fa-check"></i><b>4.2</b> Model Validation</a><ul>
<li class="chapter" data-level="4.2.1" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#iterative-model-selection"><i class="fa fa-check"></i><b>4.2.1</b> Iterative Model Selection</a></li>
<li class="chapter" data-level="4.2.2" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#summarizing-model-selection"><i class="fa fa-check"></i><b>4.2.2</b> Summarizing Model Selection</a></li>
<li class="chapter" data-level="4.2.3" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#out-of-sample-validation"><i class="fa fa-check"></i><b>4.2.3</b> Out of Sample Validation</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:ModifiedData"><i class="fa fa-check"></i><b>4.3</b> Modified Data</a><ul>
<li class="chapter" data-level="4.3.1" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#parametric-estimation-using-modified-data"><i class="fa fa-check"></i><b>4.3.1</b> Parametric Estimation using Modified Data</a></li>
<li class="chapter" data-level="4.3.2" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#nonparametric-estimation-using-modified-data"><i class="fa fa-check"></i><b>4.3.2</b> Nonparametric Estimation using Modified Data</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:BayesInference"><i class="fa fa-check"></i><b>4.4</b> Bayesian Inference</a><ul>
<li class="chapter" data-level="4.4.1" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#bayesian-model"><i class="fa fa-check"></i><b>4.4.1</b> Bayesian Model</a></li>
<li class="chapter" data-level="4.4.2" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#decision-analysis"><i class="fa fa-check"></i><b>4.4.2</b> Decision Analysis</a></li>
<li class="chapter" data-level="4.4.3" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#posterior-distribution"><i class="fa fa-check"></i><b>4.4.3</b> Posterior Distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#exercises-2"><i class="fa fa-check"></i><b>4.5</b> Exercises</a></li>
<li class="chapter" data-level="" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#technical-supplement-a.-gini-statistic"><i class="fa fa-check"></i>Technical Supplement A. Gini Statistic</a><ul>
<li class="chapter" data-level="" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#ts-a.1.-the-classic-lorenz-curve"><i class="fa fa-check"></i>TS A.1. The Classic Lorenz Curve</a></li>
<li class="chapter" data-level="" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#ts-a.2.-ordered-lorenz-curve-and-the-gini-index"><i class="fa fa-check"></i>TS A.2. Ordered Lorenz Curve and the Gini Index</a></li>
<li class="chapter" data-level="" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#ts-a.3.-out-of-sample-validation"><i class="fa fa-check"></i>TS A.3. Out-of-Sample Validation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html"><i class="fa fa-check"></i><b>5</b> Aggregate Loss Models</a><ul>
<li class="chapter" data-level="5.1" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#individual-risk-model"><i class="fa fa-check"></i><b>5.2</b> Individual Risk Model</a></li>
<li class="chapter" data-level="5.3" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#collective-risk-model"><i class="fa fa-check"></i><b>5.3</b> Collective Risk Model</a><ul>
<li class="chapter" data-level="5.3.1" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#moments-and-distribution"><i class="fa fa-check"></i><b>5.3.1</b> Moments and Distribution</a></li>
<li class="chapter" data-level="5.3.2" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#stop-loss-insurance"><i class="fa fa-check"></i><b>5.3.2</b> Stop-loss Insurance</a></li>
<li class="chapter" data-level="5.3.3" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#analytic-results"><i class="fa fa-check"></i><b>5.3.3</b> Analytic Results</a></li>
<li class="chapter" data-level="5.3.4" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#tweedie-distribution"><i class="fa fa-check"></i><b>5.3.4</b> Tweedie Distribution</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#computing-the-aggregate-claims-distribution"><i class="fa fa-check"></i><b>5.4</b> Computing the Aggregate Claims Distribution</a><ul>
<li class="chapter" data-level="5.4.1" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#recursive-method"><i class="fa fa-check"></i><b>5.4.1</b> Recursive Method</a></li>
<li class="chapter" data-level="5.4.2" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#simulation"><i class="fa fa-check"></i><b>5.4.2</b> Simulation</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#effects-of-coverage-modifications"><i class="fa fa-check"></i><b>5.5</b> Effects of Coverage Modifications</a><ul>
<li class="chapter" data-level="5.5.1" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#impact-of-exposure-on-frequency"><i class="fa fa-check"></i><b>5.5.1</b> Impact of Exposure on Frequency</a></li>
<li class="chapter" data-level="5.5.2" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#impact-of-deductibles-on-claim-frequency"><i class="fa fa-check"></i><b>5.5.2</b> Impact of Deductibles on Claim Frequency</a></li>
<li class="chapter" data-level="5.5.3" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#impact-of-policy-modifications-on-aggregate-claims"><i class="fa fa-check"></i><b>5.5.3</b> Impact of Policy Modifications on Aggregate Claims</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="simulation-1.html"><a href="simulation-1.html"><i class="fa fa-check"></i><b>6</b> Simulation</a><ul>
<li class="chapter" data-level="6.1" data-path="simulation-1.html"><a href="simulation-1.html#generating-independent-uniform-observations"><i class="fa fa-check"></i><b>6.1</b> Generating Independent Uniform Observations</a></li>
<li class="chapter" data-level="6.2" data-path="simulation-1.html"><a href="simulation-1.html#inverse-transform"><i class="fa fa-check"></i><b>6.2</b> Inverse Transform</a></li>
<li class="chapter" data-level="6.3" data-path="simulation-1.html"><a href="simulation-1.html#how-many-simulated-values"><i class="fa fa-check"></i><b>6.3</b> How Many Simulated Values?</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="C-PremCalc.html"><a href="C-PremCalc.html"><i class="fa fa-check"></i><b>7</b> Premium Calcuations Fundamentals</a></li>
<li class="chapter" data-level="8" data-path="C-RiskClass.html"><a href="C-RiskClass.html"><i class="fa fa-check"></i><b>8</b> Risk Classification</a><ul>
<li class="chapter" data-level="8.1" data-path="C-RiskClass.html"><a href="C-RiskClass.html#introduction-1"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="C-Credibility.html"><a href="C-Credibility.html"><i class="fa fa-check"></i><b>9</b> Experience Rating using Credibility Theory</a></li>
<li class="chapter" data-level="10" data-path="C-PortMgt.html"><a href="C-PortMgt.html"><i class="fa fa-check"></i><b>10</b> Portfolio Management including Reinsurance</a><ul>
<li class="chapter" data-level="10.1" data-path="C-PortMgt.html"><a href="C-PortMgt.html#S:Tails"><i class="fa fa-check"></i><b>10.1</b> Tails of Distributions</a></li>
<li class="chapter" data-level="10.2" data-path="C-PortMgt.html"><a href="C-PortMgt.html#S:RiskMeasure"><i class="fa fa-check"></i><b>10.2</b> Measures of Risk</a></li>
<li class="chapter" data-level="10.3" data-path="C-PortMgt.html"><a href="C-PortMgt.html#S:Reinsurance"><i class="fa fa-check"></i><b>10.3</b> Reinsurance</a><ul>
<li class="chapter" data-level="10.3.1" data-path="C-PortMgt.html"><a href="C-PortMgt.html#proportional-reinsurance"><i class="fa fa-check"></i><b>10.3.1</b> Proportional Reinsurance</a></li>
<li class="chapter" data-level="10.3.2" data-path="C-PortMgt.html"><a href="C-PortMgt.html#non-proportional-reinsurance"><i class="fa fa-check"></i><b>10.3.2</b> Non-Proportional Reinsurance</a></li>
<li class="chapter" data-level="10.3.3" data-path="C-PortMgt.html"><a href="C-PortMgt.html#additional-reinsurance-treaties"><i class="fa fa-check"></i><b>10.3.3</b> Additional Reinsurance Treaties</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="C-LossReserves.html"><a href="C-LossReserves.html"><i class="fa fa-check"></i><b>11</b> Loss Reserving</a></li>
<li class="chapter" data-level="12" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html"><i class="fa fa-check"></i><b>12</b> Experience Rating using Bonus-Malus</a></li>
<li class="chapter" data-level="13" data-path="data-systems.html"><a href="data-systems.html"><i class="fa fa-check"></i><b>13</b> Data Systems</a><ul>
<li class="chapter" data-level="13.1" data-path="data-systems.html"><a href="data-systems.html#data"><i class="fa fa-check"></i><b>13.1</b> Data</a><ul>
<li class="chapter" data-level="13.1.1" data-path="data-systems.html"><a href="data-systems.html#data-types-and-sources"><i class="fa fa-check"></i><b>13.1.1</b> Data Types and Sources</a></li>
<li class="chapter" data-level="13.1.2" data-path="data-systems.html"><a href="data-systems.html#data-structures-and-storage"><i class="fa fa-check"></i><b>13.1.2</b> Data Structures and Storage</a></li>
<li class="chapter" data-level="13.1.3" data-path="data-systems.html"><a href="data-systems.html#data-quality"><i class="fa fa-check"></i><b>13.1.3</b> Data Quality</a></li>
<li class="chapter" data-level="13.1.4" data-path="data-systems.html"><a href="data-systems.html#data-cleaning"><i class="fa fa-check"></i><b>13.1.4</b> Data Cleaning</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="data-systems.html"><a href="data-systems.html#data-analysis-preliminary"><i class="fa fa-check"></i><b>13.2</b> Data Analysis Preliminary</a><ul>
<li class="chapter" data-level="13.2.1" data-path="data-systems.html"><a href="data-systems.html#S:process"><i class="fa fa-check"></i><b>13.2.1</b> Data Analysis Process</a></li>
<li class="chapter" data-level="13.2.2" data-path="data-systems.html"><a href="data-systems.html#exploratory-versus-confirmatory"><i class="fa fa-check"></i><b>13.2.2</b> Exploratory versus Confirmatory</a></li>
<li class="chapter" data-level="13.2.3" data-path="data-systems.html"><a href="data-systems.html#supervised-versus-unsupervised"><i class="fa fa-check"></i><b>13.2.3</b> Supervised versus Unsupervised</a></li>
<li class="chapter" data-level="13.2.4" data-path="data-systems.html"><a href="data-systems.html#parametric-versus-nonparametric"><i class="fa fa-check"></i><b>13.2.4</b> Parametric versus Nonparametric</a></li>
<li class="chapter" data-level="13.2.5" data-path="data-systems.html"><a href="data-systems.html#S:expred"><i class="fa fa-check"></i><b>13.2.5</b> Explanation versus Prediction</a></li>
<li class="chapter" data-level="13.2.6" data-path="data-systems.html"><a href="data-systems.html#data-modeling-versus-algorithmic-modeling"><i class="fa fa-check"></i><b>13.2.6</b> Data Modeling versus Algorithmic Modeling</a></li>
<li class="chapter" data-level="13.2.7" data-path="data-systems.html"><a href="data-systems.html#big-data-analysis"><i class="fa fa-check"></i><b>13.2.7</b> Big Data Analysis</a></li>
<li class="chapter" data-level="13.2.8" data-path="data-systems.html"><a href="data-systems.html#reproducible-analysis"><i class="fa fa-check"></i><b>13.2.8</b> Reproducible Analysis</a></li>
<li class="chapter" data-level="13.2.9" data-path="data-systems.html"><a href="data-systems.html#ethical-issues"><i class="fa fa-check"></i><b>13.2.9</b> Ethical Issues</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="data-systems.html"><a href="data-systems.html#data-analysis-techniques"><i class="fa fa-check"></i><b>13.3</b> Data Analysis Techniques</a><ul>
<li class="chapter" data-level="13.3.1" data-path="data-systems.html"><a href="data-systems.html#exploratory-techniques"><i class="fa fa-check"></i><b>13.3.1</b> Exploratory Techniques</a></li>
<li class="chapter" data-level="13.3.2" data-path="data-systems.html"><a href="data-systems.html#descriptive-statistics"><i class="fa fa-check"></i><b>13.3.2</b> Descriptive Statistics</a></li>
<li class="chapter" data-level="13.3.3" data-path="data-systems.html"><a href="data-systems.html#cluster-analysis"><i class="fa fa-check"></i><b>13.3.3</b> Cluster Analysis</a></li>
<li class="chapter" data-level="13.3.4" data-path="data-systems.html"><a href="data-systems.html#confirmatory-techniques"><i class="fa fa-check"></i><b>13.3.4</b> Confirmatory Techniques</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="data-systems.html"><a href="data-systems.html#some-r-functions"><i class="fa fa-check"></i><b>13.4</b> Some R Functions</a></li>
<li class="chapter" data-level="13.5" data-path="data-systems.html"><a href="data-systems.html#summary"><i class="fa fa-check"></i><b>13.5</b> Summary</a></li>
<li class="chapter" data-level="13.6" data-path="data-systems.html"><a href="data-systems.html#further-resources-and-contributors"><i class="fa fa-check"></i><b>13.6</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="dependence-modeling.html"><a href="dependence-modeling.html"><i class="fa fa-check"></i><b>14</b> Dependence Modeling</a><ul>
<li class="chapter" data-level="14.1" data-path="dependence-modeling.html"><a href="dependence-modeling.html#S:VarTypes"><i class="fa fa-check"></i><b>14.1</b> Variable Types</a><ul>
<li class="chapter" data-level="14.1.1" data-path="dependence-modeling.html"><a href="dependence-modeling.html#S:QuaVar"><i class="fa fa-check"></i><b>14.1.1</b> Qualitative Variables</a></li>
<li class="chapter" data-level="14.1.2" data-path="dependence-modeling.html"><a href="dependence-modeling.html#S:QuanVar"><i class="fa fa-check"></i><b>14.1.2</b> Quantitative Variables</a></li>
<li class="chapter" data-level="14.1.3" data-path="dependence-modeling.html"><a href="dependence-modeling.html#multivariate-variables"><i class="fa fa-check"></i><b>14.1.3</b> Multivariate Variables</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="dependence-modeling.html"><a href="dependence-modeling.html#S:Measures"><i class="fa fa-check"></i><b>14.2</b> Classic Measures of Scalar Associations</a><ul>
<li class="chapter" data-level="14.2.1" data-path="dependence-modeling.html"><a href="dependence-modeling.html#association-measures-for-quantitative-variables"><i class="fa fa-check"></i><b>14.2.1</b> Association Measures for Quantitative Variables</a></li>
<li class="chapter" data-level="14.2.2" data-path="dependence-modeling.html"><a href="dependence-modeling.html#rank-based-measures"><i class="fa fa-check"></i><b>14.2.2</b> Rank Based Measures</a></li>
<li class="chapter" data-level="14.2.3" data-path="dependence-modeling.html"><a href="dependence-modeling.html#nominal-variables"><i class="fa fa-check"></i><b>14.2.3</b> Nominal Variables</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="dependence-modeling.html"><a href="dependence-modeling.html#S:Copula"><i class="fa fa-check"></i><b>14.3</b> Introduction to Copula</a></li>
<li class="chapter" data-level="14.4" data-path="dependence-modeling.html"><a href="dependence-modeling.html#S:CopAppl"><i class="fa fa-check"></i><b>14.4</b> Application Using Copulas</a><ul>
<li class="chapter" data-level="14.4.1" data-path="dependence-modeling.html"><a href="dependence-modeling.html#data-description"><i class="fa fa-check"></i><b>14.4.1</b> Data Description</a></li>
<li class="chapter" data-level="14.4.2" data-path="dependence-modeling.html"><a href="dependence-modeling.html#marginal-models"><i class="fa fa-check"></i><b>14.4.2</b> Marginal Models</a></li>
<li class="chapter" data-level="14.4.3" data-path="dependence-modeling.html"><a href="dependence-modeling.html#probability-integral-transformation"><i class="fa fa-check"></i><b>14.4.3</b> Probability Integral Transformation</a></li>
<li class="chapter" data-level="14.4.4" data-path="dependence-modeling.html"><a href="dependence-modeling.html#joint-modeling-with-copula-function"><i class="fa fa-check"></i><b>14.4.4</b> Joint Modeling with Copula Function</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="dependence-modeling.html"><a href="dependence-modeling.html#S:CopTyp"><i class="fa fa-check"></i><b>14.5</b> Types of Copulas</a><ul>
<li class="chapter" data-level="14.5.1" data-path="dependence-modeling.html"><a href="dependence-modeling.html#elliptical-copulas"><i class="fa fa-check"></i><b>14.5.1</b> Elliptical Copulas</a></li>
<li class="chapter" data-level="14.5.2" data-path="dependence-modeling.html"><a href="dependence-modeling.html#archimedian-copulas"><i class="fa fa-check"></i><b>14.5.2</b> Archimedian Copulas</a></li>
<li class="chapter" data-level="14.5.3" data-path="dependence-modeling.html"><a href="dependence-modeling.html#properties-of-copulas"><i class="fa fa-check"></i><b>14.5.3</b> Properties of Copulas</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="dependence-modeling.html"><a href="dependence-modeling.html#S:CopImp"><i class="fa fa-check"></i><b>14.6</b> Why is Dependence Modeling Important?</a></li>
<li class="chapter" data-level="" data-path="dependence-modeling.html"><a href="dependence-modeling.html#technical-supplement-a.-other-classic-measures-of-scalar-associations"><i class="fa fa-check"></i>Technical Supplement A. Other Classic Measures of Scalar Associations</a><ul>
<li class="chapter" data-level="" data-path="dependence-modeling.html"><a href="dependence-modeling.html#a.1.-blomqvists-beta"><i class="fa fa-check"></i>A.1. Blomqvist’s Beta</a></li>
<li class="chapter" data-level="" data-path="dependence-modeling.html"><a href="dependence-modeling.html#a.2.-nonparametric-approach-using-spearman-correlation-with-tied-ranks"><i class="fa fa-check"></i>A.2. Nonparametric Approach Using Spearman Correlation with Tied Ranks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="C-AppA.html"><a href="C-AppA.html"><i class="fa fa-check"></i><b>15</b> Appendix A: Review of Statistical Inference</a><ul>
<li class="chapter" data-level="15.1" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:BASIC"><i class="fa fa-check"></i><b>15.1</b> Basic Concepts</a><ul>
<li class="chapter" data-level="15.1.1" data-path="C-AppA.html"><a href="C-AppA.html#random-sampling"><i class="fa fa-check"></i><b>15.1.1</b> Random Sampling</a></li>
<li class="chapter" data-level="15.1.2" data-path="C-AppA.html"><a href="C-AppA.html#sampling-distribution"><i class="fa fa-check"></i><b>15.1.2</b> Sampling Distribution</a></li>
<li class="chapter" data-level="15.1.3" data-path="C-AppA.html"><a href="C-AppA.html#central-limit-theorem"><i class="fa fa-check"></i><b>15.1.3</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:PE"><i class="fa fa-check"></i><b>15.2</b> Point Estimation and Properties</a><ul>
<li class="chapter" data-level="15.2.1" data-path="C-AppA.html"><a href="C-AppA.html#method-of-moments-estimation"><i class="fa fa-check"></i><b>15.2.1</b> Method of Moments Estimation</a></li>
<li class="chapter" data-level="15.2.2" data-path="C-AppA.html"><a href="C-AppA.html#maximum-likelihood-estimation-1"><i class="fa fa-check"></i><b>15.2.2</b> Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:IE"><i class="fa fa-check"></i><b>15.3</b> Interval Estimation</a><ul>
<li class="chapter" data-level="15.3.1" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:IE:ED"><i class="fa fa-check"></i><b>15.3.1</b> Exact Distribution for Normal Sample Mean</a></li>
<li class="chapter" data-level="15.3.2" data-path="C-AppA.html"><a href="C-AppA.html#large-sample-properties-of-mle"><i class="fa fa-check"></i><b>15.3.2</b> Large-sample Properties of MLE</a></li>
<li class="chapter" data-level="15.3.3" data-path="C-AppA.html"><a href="C-AppA.html#confidence-interval"><i class="fa fa-check"></i><b>15.3.3</b> Confidence Interval</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:HT"><i class="fa fa-check"></i><b>15.4</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="15.4.1" data-path="C-AppA.html"><a href="C-AppA.html#basic-concepts"><i class="fa fa-check"></i><b>15.4.1</b> Basic Concepts</a></li>
<li class="chapter" data-level="15.4.2" data-path="C-AppA.html"><a href="C-AppA.html#student-t-test-based-on-mle"><i class="fa fa-check"></i><b>15.4.2</b> Student-<span class="math inline">\(t\)</span> test based on MLE</a></li>
<li class="chapter" data-level="15.4.3" data-path="C-AppA.html"><a href="C-AppA.html#likelihood-ratio-test"><i class="fa fa-check"></i><b>15.4.3</b> Likelihood Ratio Test</a></li>
<li class="chapter" data-level="15.4.4" data-path="C-AppA.html"><a href="C-AppA.html#information-criteria"><i class="fa fa-check"></i><b>15.4.4</b> Information Criteria</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="C-AppB.html"><a href="C-AppB.html"><i class="fa fa-check"></i><b>16</b> Appendix B: Iterated Expectations</a><ul>
<li class="chapter" data-level="16.1" data-path="C-AppB.html"><a href="C-AppB.html#S:AppB:CD"><i class="fa fa-check"></i><b>16.1</b> Conditional Distribution and Conditional Expectation</a><ul>
<li class="chapter" data-level="16.1.1" data-path="C-AppB.html"><a href="C-AppB.html#conditional-distribution"><i class="fa fa-check"></i><b>16.1.1</b> Conditional Distribution</a></li>
<li class="chapter" data-level="16.1.2" data-path="C-AppB.html"><a href="C-AppB.html#conditional-expectation-and-conditional-variance"><i class="fa fa-check"></i><b>16.1.2</b> Conditional Expectation and Conditional Variance</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="C-AppB.html"><a href="C-AppB.html#S:AppB:IE"><i class="fa fa-check"></i><b>16.2</b> Iterated Expectations and Total Variance</a><ul>
<li class="chapter" data-level="16.2.1" data-path="C-AppB.html"><a href="C-AppB.html#law-of-iterated-expectations"><i class="fa fa-check"></i><b>16.2.1</b> Law of Iterated Expectations</a></li>
<li class="chapter" data-level="16.2.2" data-path="C-AppB.html"><a href="C-AppB.html#law-of-total-variance"><i class="fa fa-check"></i><b>16.2.2</b> Law of Total Variance</a></li>
<li class="chapter" data-level="16.2.3" data-path="C-AppB.html"><a href="C-AppB.html#application"><i class="fa fa-check"></i><b>16.2.3</b> Application</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="C-AppC.html"><a href="C-AppC.html"><i class="fa fa-check"></i><b>17</b> Appendix C: Maximum Likelihood Theory</a><ul>
<li class="chapter" data-level="17.1" data-path="C-AppC.html"><a href="C-AppC.html#S:AppC:LF"><i class="fa fa-check"></i><b>17.1</b> Likelihood Function</a><ul>
<li class="chapter" data-level="17.1.1" data-path="C-AppC.html"><a href="C-AppC.html#likelihood-and-log-likelihood-functions"><i class="fa fa-check"></i><b>17.1.1</b> Likelihood and Log-likelihood Functions</a></li>
<li class="chapter" data-level="17.1.2" data-path="C-AppC.html"><a href="C-AppC.html#properties-of-likelihood-functions"><i class="fa fa-check"></i><b>17.1.2</b> Properties of Likelihood Functions</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="C-AppC.html"><a href="C-AppC.html#S:AppC:MLE"><i class="fa fa-check"></i><b>17.2</b> Maximum Likelihood Estimators</a><ul>
<li class="chapter" data-level="17.2.1" data-path="C-AppC.html"><a href="C-AppC.html#definition-and-derivation-of-mle"><i class="fa fa-check"></i><b>17.2.1</b> Definition and Derivation of MLE</a></li>
<li class="chapter" data-level="17.2.2" data-path="C-AppC.html"><a href="C-AppC.html#asymptotic-properties-of-mle"><i class="fa fa-check"></i><b>17.2.2</b> Asymptotic Properties of MLE</a></li>
<li class="chapter" data-level="17.2.3" data-path="C-AppC.html"><a href="C-AppC.html#use-of-maximum-likelihood-estimation"><i class="fa fa-check"></i><b>17.2.3</b> Use of Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="C-AppC.html"><a href="C-AppC.html#S:AppC:SI"><i class="fa fa-check"></i><b>17.3</b> Statistical Inference Based on Maximum Likelhood Estimation</a><ul>
<li class="chapter" data-level="17.3.1" data-path="C-AppC.html"><a href="C-AppC.html#hypothesis-testing"><i class="fa fa-check"></i><b>17.3.1</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="17.3.2" data-path="C-AppC.html"><a href="C-AppC.html#mle-and-model-validation"><i class="fa fa-check"></i><b>17.3.2</b> MLE and Model Validation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://ewfrees.github.io/Loss-Data-Analytics/" target="blank">Loss Data Analytics on GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Loss Data Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="C:Frequency" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Frequency Distributions</h1>
<p><em>Chapter Preview</em>. These are overheads from a course that provides some structure for this chapter.</p>
<div id="how-frequency-augments-severity-information" class="section level2">
<h2><span class="header-section-number">2.1</span> How Frequency Augments Severity Information</h2>
<div id="basic-terminology" class="section level4">
<h4><span class="header-section-number">2.1.0.1</span> Basic Terminology</h4>
<ul>
<li><p><strong>Claim</strong> - indemnification upon the occurrence of an insured event</p>
<ul>
<li><strong>Loss</strong> - some authors use claim and loss interchangeably, others think of loss as the amount suffered by the insured whereas claim is the amount paid by the insurer</li>
</ul></li>
<li><p><strong>Frequency</strong> - how often an insured event occurs, typically within a policy contract</p></li>
<li><p><strong>Count</strong> - In this chapter, we focus on count random variables that represent the number of claims, that is, how frequently an event occurs</p></li>
<li><p><strong>Severity</strong> - Amount, or size, of each payment for an insured event</p></li>
</ul>
</div>
<div id="the-importance-of-frequency" class="section level4">
<h4><span class="header-section-number">2.1.0.2</span> The Importance of Frequency</h4>
<ul>
<li><p>Insurers pay claims in monetary units, e.g., US dollars. So, why should they care about how frequently claims occur?</p></li>
<li><p>Many ways to use claims modeling – easiest to motivate in terms of pricing for personal lines insurance</p>
<ul>
<li><p>Recall from Chapter 1 that setting the price of an insurance good can be a perplexing problem.</p></li>
<li><p>In manufacturing, the cost of a good is (relatively) known</p></li>
<li><p>Other financial service areas, market prices are available</p></li>
<li><p>Insurance tradition: Start with an expected cost. Add “margins” to account for the product’s riskiness, expenses incurred in servicing the product, and a profit/surplus allowance for the insurance company.</p></li>
</ul></li>
<li><p>Think of the expected cost as the expected number of claims times the expected amount per claims, that is, expected <em>frequency times severity</em>.</p></li>
<li><p>Claim amounts, or severities, will turn out to be relatively homogeneous for many lines of business and so we begin our investigations with frequency modeling.</p></li>
</ul>
</div>
<div id="other-ways-that-frequency-augments-severity-information" class="section level4">
<h4><span class="header-section-number">2.1.0.3</span> Other Ways that Frequency Augments Severity Information</h4>
<ul>
<li><p><strong>Contractual</strong> - For example, deductibles and policy limits are often in terms of each occurrence of an insured event</p></li>
<li><p><strong>Behaviorial</strong> - Explanatory (rating) variables can have different effects on models of how often an event occurs in contrast to the size of the event.</p>
<ul>
<li>In healthcare, the decision to utilize healthcare by individuals is related primarily to personal characteristics whereas the cost per user may be more related to characteristics of the healthcare provider (such as the physician).</li>
</ul></li>
<li><p><strong>Databases</strong>. Many insurers keep separate data files that suggest developing separate frequency and severity models. This recording process makes it natural for insurers to model the frequency and severity as separate processes.</p>
<ul>
<li><p>Policyholder file that is established when a policy is written. This file records much underwriting information about the insured(s), such as age, gender and prior claims experience, policy information such as coverage, deductibles and limitations, as well as the insurance claims event.</p></li>
<li><p>Claims file, records details of the claim against the insurer, including the amount.</p></li>
<li><p>(There may also be a “payments” file that records the timing of the payments although we shall not deal with that here.)</p></li>
</ul></li>
<li><p><strong>Regulatory and Administrative</strong></p>
<ul>
<li><p>Regulators routinely require the reporting of claims numbers as well as amounts.</p></li>
<li><p>This may be due to the fact that there can be alternative definitions of an “amount,” e.g., paid versus incurred, and there is less potential error when reporting claim numbers.</p></li>
</ul></li>
</ul>
</div>
</div>
<div id="basic-frequency-distributions" class="section level2">
<h2><span class="header-section-number">2.2</span> Basic Frequency Distributions</h2>
<div id="foundations" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Foundations</h3>
<ul>
<li><p>Claim count <span class="math inline">\(N\)</span> has support on the non-negative integers <span class="math inline">\(k=0,1,2, \ldots\)</span>.</p></li>
<li><p>The <strong>probability mass function</strong> is denoted as <span class="math inline">\(\Pr(N = k) = p_k\)</span></p></li>
<li><p>We can summarize the distribution through its <strong>moments</strong></p>
<ul>
<li><p>The <strong>mean</strong>, or first moment, is</p>
<p><span class="math display">\[\mathrm{E~} N = \mu_1 = \mu = \sum^{\infty}_{k=0} k p_k .\]</span></p></li>
<li><p>More generally, the <span class="math inline">\(r\)</span>th moment is <span class="math display">\[\mathrm{E~} N^r = \mu_r^{\prime} = \sum^{\infty}_{k=0} k^r p_k .\]</span></p></li>
<li><p>The <strong>variance</strong> is <span class="math display">\[\mathrm{Var~} N = \mathrm{E~} (N-\mu)^2 = \mathrm{E~} N^2 - \mu^2\]</span></p></li>
</ul></li>
<li><p>Also recall the <strong>moment generating function</strong> <span class="math display">\[M_N(t) = \mathrm{E~}e^{tN} = \sum^{\infty}_{k=0} e^{tk} p_k .\]</span></p></li>
</ul>
</div>
<div id="probability-generating-function" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Probability Generating Function</h3>
<ul>
<li><p>The <strong>probability generating function</strong> is <span class="math display">\[\begin{aligned}
\mathrm{P}(z) &amp;= \mathrm{E~}z^N = \mathrm{E~}\exp{(N \ln z)} = M_N(\ln{z})\\
&amp;= \sum^{\infty}_{k=0} z^k p_k .\end{aligned}\]</span></p></li>
<li><p>By taking the <span class="math inline">\(m\)</span>th derivative, we see that <span class="math display">\[\begin{aligned}
\left. P^{(m)}(z)\right|_{z=0} &amp;= \frac{\partial^m }{\partial z^m} P(z)|_{z=0} = p_m m!\end{aligned}\]</span> the pgf “generates” the probabilities.</p></li>
<li><p>Further, the pgf can be used to generate moments <span class="math display">\[\begin{aligned}
P^{(1)}(1) &amp;= \sum k p_k = \mathrm{E~}N .\end{aligned}\]</span> and <span class="math display">\[P^{(2)}(1) = \mathrm{E~}N(N-1).\]</span></p></li>
</ul>
</div>
<div id="important-frequency-distributions" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Important Frequency Distributions</h3>
<ul>
<li><p>The three important (in insurance) frequency distributions are:</p>
<ul>
<li><p>Poisson</p></li>
<li><p>Negative binomial</p></li>
<li><p>Binomial</p></li>
</ul></li>
<li><p>They are important because:</p>
<ul>
<li><p>They fit well many insurance data sets of interest</p></li>
<li><p>They provide the basis for more complex distributions that even better approximate real situations of interest to us</p></li>
</ul></li>
</ul>
<div id="poisson-distribution" class="section level4">
<h4><span class="header-section-number">2.2.3.1</span> Poisson Distribution</h4>
<ul>
<li><p>This distribution has parameter <span class="math inline">\(\lambda\)</span>, probability mass function <span class="math display">\[p_k = \frac{e^{-\lambda}\lambda^k}{k!}\]</span> and pgf <span class="math display">\[\begin{aligned}
P(z) &amp;= M_N (\ln z) = \exp(\lambda(z-1))\end{aligned}\]</span></p></li>
<li><p>The expectation is <span class="math inline">\(\mathrm{E~}N = \lambda\)</span> which is the same as the variance, <span class="math inline">\(\mathrm{Var~}N = \lambda\)</span>.</p></li>
</ul>
</div>
<div id="negative-binomial-distribution" class="section level4">
<h4><span class="header-section-number">2.2.3.2</span> Negative Binomial Distribution</h4>
<ul>
<li><p>This distribution has parameters <span class="math inline">\((r, \beta)\)</span>, probability mass function (pmf) <span class="math display">\[p_k = {k+r-1\choose k} \left(\frac{1}{1+\beta}\right)^r \left(\frac{\beta}{1+\beta}\right)^k\]</span> and probability generating function (pgf) <span class="math display">\[\begin{aligned}
P(z) &amp;= (1-\beta(z-1))^{-r} \end{aligned}\]</span></p></li>
<li><p>The expectation is <span class="math inline">\(\mathrm{E~}N = r\beta\)</span> and the variance is <span class="math inline">\(\mathrm{Var~}N = r\beta(1+\beta)\)</span>.</p></li>
<li><p>When <span class="math inline">\(\beta&gt;0\)</span>, we have <span class="math inline">\(\mathrm{Var~}N &gt;\mathrm{E~}N\)</span>. This distribution is said to be <strong>overdispersed</strong> (relative to the Poisson).</p></li>
</ul>
</div>
<div id="binomial-distribution" class="section level4">
<h4><span class="header-section-number">2.2.3.3</span> Binomial Distribution</h4>
<ul>
<li><p>This distribution has parameters <span class="math inline">\((m,q)\)</span>, probability mass function <span class="math display">\[p_k = {m\choose k} q^k (1-q)^{m-k}\]</span> and pgf <span class="math display">\[\begin{aligned}
P(z) &amp;= (1+q(z-1))^m\end{aligned}\]</span></p></li>
<li><p>The mean is <span class="math inline">\(\mathrm{E~}N = mq\)</span> and the variance is <span class="math inline">\(\mathrm{Var~}N = mq(1-q)\)</span>.</p></li>
</ul>
</div>
</div>
</div>
<div id="the-a-b-0-class" class="section level2">
<h2><span class="header-section-number">2.3</span> The (a, b, 0) Class</h2>
<ul>
<li><p>Recall the notation <span class="math inline">\(p_k= \Pr(N = k)\)</span>.</p></li>
<li><p><em>Definition</em>. A count distribution is a member of the <strong>(<span class="math inline">\(a, b\)</span>, 0) class</strong> if the probabilities <span class="math inline">\(p_k\)</span> satisfy <span class="math display">\[\frac{p_k}{p_{k-1}}=a+\frac{b}{k},\]</span> for constants <span class="math inline">\(a,b\)</span> and for $k=1,2,3, $.</p>
<ul>
<li><p>There are only three distributions that are members of the (<span class="math inline">\(a,b\)</span>,0) class. They are the Poisson (<span class="math inline">\(a=0\)</span>), binomial(<span class="math inline">\(a&lt;0\)</span>), and negative binomial (<span class="math inline">\(a&gt;0\)</span>).</p></li>
<li><p>The recursive expression provides a computationally efficient way to generate probabilities.</p></li>
</ul></li>
</ul>
<div id="the-a-b-0-class---special-cases" class="section level4">
<h4><span class="header-section-number">2.3.0.1</span> The (a, b, 0) Class - Special Cases</h4>
<ul>
<li><p><em>Example: Poisson Distribution</em>.</p>
<ul>
<li>Recall the pmf <span class="math inline">\(p_k =\frac{\lambda^k}{k!}e^{-\lambda}\)</span>. Examining the ratio, <span class="math display">\[\frac{p_k}{p_{k-1}} = \frac{\lambda^k/k!}{\lambda^{k-1}/(k-1)!}\frac{e^{-\lambda}}{e^{-\lambda}}= \frac{\lambda}{k}\]</span> Thus, the Poisson is a member of the (<span class="math inline">\(a, b\)</span>, 0) class with <span class="math inline">\(a = 0\)</span>, <span class="math inline">\(b = \lambda\)</span>, and initial starting value <span class="math inline">\(p_0 = e^{-\lambda}\)</span>.</li>
</ul>
<p><strong>Other special cases</strong> (Please check)</p></li>
<li><p><em>Example: Binomial Distribution</em>. Use a similar technique to check that the binomial distribution is a member of the (<span class="math inline">\(a, b\)</span>, 0) class with <span class="math inline">\(a = \frac{-q}{1-q},\)</span> <span class="math inline">\(b = \frac{(m+1)q}{1-q},\)</span> and initial starting value <span class="math inline">\(p_0 = (1-q)^m\)</span>.</p></li>
</ul>
<p><strong>Another special case of the (<span class="math inline">\(a, b\)</span>, 0) Class</strong> (Please check)</p>
<ul>
<li><em>Example: Negative Binomial Distribution</em>. Check that the negative binomial distribution is a member of the (<span class="math inline">\(a, b\)</span>, 0) class with <span class="math inline">\(a = \frac{\beta}{1+\beta},\)</span> <span class="math inline">\(b = \frac{(r-1)\beta}{1+\beta},\)</span> and initial starting value <span class="math inline">\(p_0 = (1+\beta)^{-r}\)</span>.</li>
</ul>
<p><em>Exercise.</em> A discrete probability distribution has the following properties <span class="math display">\[\begin{aligned}
p_k&amp;=c\left( 1+\frac{2}{k}\right) p_{k-1} \:\:\: k=1,2,3,\\
p_1&amp;= \frac{9}{256}\end{aligned}\]</span> Determine the expected value of this discrete random variable (Ans: 9)</p>
</div>
<div id="the-a-b-0-class---example" class="section level3">
<h3><span class="header-section-number">2.3.1</span> The (a, b, 0) Class - Example</h3>
<p><em>Exercise.</em> A discrete probability distribution has the following properties <span class="math display">\[\begin{aligned}
\Pr(N=k) = \left( \frac{3k+9}{8k}\right) \Pr(N=k-1), ~~~k=1,2,3,\ldots\end{aligned}\]</span> Determine the value of <span class="math inline">\(\Pr(N=3)\)</span>. (Ans: 0.1609)</p>
</div>
</div>
<div id="estimating-frequency-distributions" class="section level2">
<h2><span class="header-section-number">2.4</span> Estimating Frequency Distributions</h2>
<div id="parameter-estimation" class="section level4">
<h4><span class="header-section-number">2.4.0.1</span> Parameter estimation</h4>
<ul>
<li><p>The customary method of estimation is <strong>maximum likelihood</strong>.</p></li>
<li><p>To provide intuition, we outline the ideas in the context of Bernoulli distribution.</p>
<ul>
<li><p>This is a special case of the binomial distribution with <span class="math inline">\(m=1\)</span></p></li>
<li><p>For count distributions, either there is a claim <span class="math inline">\(N=1\)</span> or not <span class="math inline">\(N=0\)</span>. The probability mass function is <span class="math display">\[p_k = \Pr (N=k) = \left\{ \begin{array}{ll}
1-q &amp; \mathrm{if}\ k=0 \\
q&amp; \mathrm{if}\ k=1
\end{array} \right. .\]</span></p></li>
</ul></li>
<li><p>The Statistical Inference Problem</p>
<ul>
<li><p>Now suppose that we have a collection of independent random variables. The <span class="math inline">\(i\)</span>th variable is denoted as <span class="math inline">\(N_i\)</span>. Further assume they have the same Bernoulli distribution with parameter <span class="math inline">\(q\)</span>.</p></li>
<li><p>In statistical inference, we assume that we observe a sample of such random variables. The observed value of the <span class="math inline">\(i\)</span>th random variable is <span class="math inline">\(n_i\)</span>. Assuming that the Bernoulli distribution is correct, we wish to say something about the probability parameter <span class="math inline">\(q\)</span>.</p></li>
</ul></li>
</ul>
</div>
<div id="bernoulli-likelihoods" class="section level4">
<h4><span class="header-section-number">2.4.0.2</span> Bernoulli Likelihoods</h4>
<ul>
<li><p><em>Definition</em>. The <strong>likelihood</strong> is the observed value of the mass function.</p></li>
<li><p>For a single observation, the likelihood is <span class="math display">\[\left\{
\begin{array}{ll}
1-q &amp; \mathrm{if}\ n_i=0 \\
q   &amp; \mathrm{if}\ n_i=1
\end{array}
\right. .\]</span></p></li>
<li><p>The objective of <strong>maximum likelihood estimation (MLE)</strong> is to find the parameter values that produce the largest likelihood.</p>
<ul>
<li><p>Finding the maximum of the logarithmic function yields the same solution as finding the maximum of the corresponding function.</p></li>
<li><p>Because it is generally computationally simpler, we consider the logarithmic (log-) likelihood, written as <span class="math display">\[\left\{
\begin{array}{ll}
\ln \left( 1-q\right)  &amp; \mathrm{if}\ n_i=0 \\
\ln     q              &amp; \mathrm{if}\ n_i=1
\end{array}\right. .\]</span></p></li>
</ul></li>
</ul>
</div>
<div id="bernoulli-mle" class="section level4">
<h4><span class="header-section-number">2.4.0.3</span> Bernoulli MLE</h4>
<ul>
<li><p>More compactly, the log-likelihood of a single observation is <span class="math display">\[n_i \ln q + (1-n_i)\ln ( 1-q ) ,\]</span></p></li>
<li><p>Assuming independence, the log-likelihood of the data set is <span class="math display">\[L_{Bern}(q)=\sum_i \left\{ n_i \ln q + (1-n_i)\ln ( 1-q ) \right\}\]</span></p>
<ul>
<li><p>The (log) likelihood is viewed as a function of the parameters, with the data held fixed.</p></li>
<li><p>In contrast, the joint probability mass function is viewed as a function of the realized data, with the parameters held fixed.</p></li>
</ul></li>
<li><p>The method of maximum likelihood means finding the values of <span class="math inline">\(q\)</span> that maximize the log-likelihood.</p></li>
<li><p>We began with the Bernoulli distribution in part because the log-likelihood is easy to maximize.</p></li>
<li><p>Take a derivative of <span class="math inline">\(L_{Bern}(q)\)</span> to get <span class="math display">\[\frac{\partial}{\partial q} L_{Bern}(q)=\sum_i \left\{ n_i \frac{1}{q} - (1-n_i)\frac{1}{1-q} \right\}\]</span> and solving the equation <span class="math inline">\(\frac{\partial}{\partial q} L_{Bern}(q) =0\)</span> yields <span class="math display">\[\hat{q} = \frac{\sum_i n_i}{\mathrm{sample ~size}}\]</span> or, in words, the <span class="math inline">\(MLE\)</span> <span class="math inline">\(\hat{q}\)</span> is the fraction of one’s in the sample.</p></li>
<li><p>Just to be complete, you should check, by taking derivatives, that when we solve <span class="math inline">\(\frac{\partial}{\partial q} L_{Bern}(q) =0\)</span> we are maximizing the function <span class="math inline">\(L_{Bern}(q)\)</span>, not minimizing it.</p></li>
</ul>
</div>
<div id="frequency-distributions-mle" class="section level4">
<h4><span class="header-section-number">2.4.0.4</span> Frequency Distributions MLE</h4>
<ul>
<li><p>We can readily extend this procedure to all frequency distributions</p></li>
<li><p>For notation, suppose that <span class="math inline">\(\theta\)</span> (“theta”) is a parameter that describes a given frequency distribution <span class="math inline">\(\Pr(N=k; \theta) = p_k(\theta)\)</span></p>
<ul>
<li>In later developments we will let <span class="math inline">\(\theta\)</span> be a vector but for the moment assume it to be a scalar.</li>
</ul></li>
<li><p>The log-likelihood of a a single observation is <span class="math display">\[\left\{
\begin{array}{ll}
\ln p_0(\theta) &amp; \mathrm{if}\ n_i=0 \\
\ln p_1(\theta) &amp; \mathrm{if}\ n_i=1 \\
\vdots &amp; \vdots
\end{array}
\right. .\]</span> that can be written more compactly as <span class="math display">\[\sum_k I(n_i=k) \ln p_k(\theta).\]</span> this uses the notation <span class="math inline">\(I(\cdot)\)</span> to be the indicator of a set (it returns one if the event is true and 0 otherwise).</p></li>
<li><p>Assuming independence, the log-likelihood of the data set is <span class="math display">\[L(\theta)=\sum_i \left\{ \sum_k I(n_i=k) \ln p_k(\theta) \right\} = \left\{ \sum_k m_k\ln p_k(\theta) \right\}\]</span> where we use the notation <span class="math inline">\(m_k\)</span> to denote the number of observations that are observed having count <span class="math inline">\(k\)</span>. Using notation, <span class="math inline">\(m_k = \sum_i I(n_i=k)\)</span>.</p></li>
<li><p><strong>Special Case</strong>. <em>Poisson</em>. A simple exercise in calculus yields <span class="math display">\[\hat{\lambda} =  \frac{\mathrm{number ~of ~claims}}{\mathrm{sample ~size}} = \frac{\sum_k k m_k}{\sum_k  m_k}\]</span> the average claim count.</p></li>
</ul>
</div>
</div>
<div id="other-frequency-distributions" class="section level2">
<h2><span class="header-section-number">2.5</span> Other Frequency Distributions</h2>
<ul>
<li><p>Naturally, there are many other count distributions needed in practice</p></li>
<li><p>For many insurance applications, one can work with one of our three basic distributions (binomial, Poisson, negative binomial) and allow the parameters to be a function of known explanatory variables.</p>
<ul>
<li><p>This allows us to explain claim probabilities in terms of known (to the insurer) variables such as age, sex, geographic location (territory), and so forth.</p></li>
<li><p>This field of statistical study is known as <strong>regression analysis</strong> - it is an important topic that we will not pursue in this course.</p></li>
</ul></li>
<li><p>To extend our basic count distributions to alternatives needed in practice, we consider two approaches:</p>
<ul>
<li><p>Zero truncation or modification</p></li>
<li><p>Mixing</p></li>
</ul></li>
</ul>
<div id="zero-truncation-or-modification" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Zero Truncation or Modification</h3>
<ul>
<li><p>Why truncate or modify zero?</p>
<ul>
<li><p>If we work with a database of claims, then there are no zero!</p></li>
<li><p>In personal lines (like auto), people may not want to report that first claim because they fear it will increase future insurance rates.</p></li>
</ul></li>
<li><p>Let’s modify zero probabilities in terms of the <span class="math inline">\((a,b,0)\)</span> class</p></li>
<li><p><em>Definition</em>. A count distribution is a member of the <strong>(<span class="math inline">\(a, b\)</span>, 1) class</strong> if the probabilities <span class="math inline">\(p_k\)</span> satisfy <span class="math display">\[\frac{p_k}{p_{k-1}}=a+\frac{b}{k},\]</span> for constants <span class="math inline">\(a,b\)</span> and for <span class="math inline">\(k=2,3, \ldots\)</span>.</p></li>
<li><p>Note that this starts at <span class="math inline">\(k=2\)</span>, not <span class="math inline">\(k=1\)</span>. That is, the most important thing about this definition is that the recursion starts at <span class="math inline">\(p_1\)</span>, not <span class="math inline">\(p_0\)</span>.</p></li>
<li><p>Thus, all distributions that are members of the (<span class="math inline">\(a, b\)</span>, 0) are members of the (<span class="math inline">\(a, b\)</span>, 1) class. Naturally, there are additional distributions that are members of this wider class.</p></li>
<li><p>To see how this works, pick a specific distribution in the (<span class="math inline">\(a, b\)</span>, 0) class.</p>
<ul>
<li><p>Consider <span class="math inline">\(p_k^0\)</span> to be a probability for this member of <span class="math inline">\((a,b,0)\)</span>.</p></li>
<li><p>Let <span class="math inline">\(p_k^M\)</span> be the corresponding probability for a member of <span class="math inline">\((a,b,1)\)</span>, where the <span class="math inline">\(M\)</span> stands for “modified”.</p></li>
<li><p>Pick a new probability of a zero claim, <span class="math inline">\(p_0^M\)</span>, and define <span class="math display">\[\begin{aligned}
c = \frac{1-p_0^M}{1-p_0^0} .\end{aligned}\]</span></p></li>
<li><p>We then calculate the rest of the modified distribution as <span class="math display">\[\begin{aligned}
p_k^M =c p_k^0\end{aligned}\]</span></p></li>
</ul></li>
</ul>
<div id="special-case-poisson-truncated-at-zero." class="section level4">
<h4><span class="header-section-number">2.5.1.1</span> Special Case: Poisson Truncated at Zero.</h4>
<p>For this case, we assume that <span class="math inline">\(p_0^M=0\)</span>, so that the probability of <span class="math inline">\(N=0\)</span> is zero, hence the name “truncated at zero.”</p>
<ul>
<li>For this case, we use the letter <span class="math inline">\(T\)</span> to denote probabilities instead of <span class="math inline">\(M\)</span>, so we use <span class="math inline">\(p_k^T\)</span> for probabilities. Thus, <span class="math display">\[\begin{aligned}
p_k^T&amp;=
\left \{
\begin{array}{cc}
0 &amp; k=0\\
\frac{1}{1-p_0^0}p_k^0 &amp; k \ge 1\\
\end{array}
\right.\end{aligned}\]</span></li>
</ul>
</div>
<div id="modified-poisson-example" class="section level4">
<h4><span class="header-section-number">2.5.1.2</span> Modified Poisson Example</h4>
<p><em>Example: Zero Truncated/Modified Poisson</em>. Consider a Poisson distribution with parameter <span class="math inline">\(\lambda=2\)</span>. We show how to calculate <span class="math inline">\(p_k, k=0,1,2,3\)</span>, for the usual (unmodified), truncated and a modified version with <span class="math inline">\((p_0^M=0.6)\)</span>.</p>
<p><em>Solution.</em> For the Poisson distribution as a member of the (<span class="math inline">\(a,b\)</span>,0) class, we have <span class="math inline">\(a=0\)</span> and <span class="math inline">\(b=\lambda=2\)</span>. Thus, we may use the recursion <span class="math inline">\(p_k = \lambda p_{k-1}/k= 2 p_{k-1}/k\)</span> for each type, after determining starting probabilities.</p>
<table>
<thead>
<tr class="header">
<th align="center">k</th>
<th align="center"><span class="math inline">\(p_k\)</span></th>
<th align="center"><span class="math inline">\(p_k^T\)</span></th>
<th align="center"><span class="math inline">\(p_k^M\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0</td>
<td align="center"><span class="math inline">\(p_0=e^{-\lambda}=0.135335\)</span></td>
<td align="center">0</td>
<td align="center">0.6</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center"><span class="math inline">\(p_1=p_0(0+\frac{\lambda}{1})=0.27067\)</span></td>
<td align="center"><span class="math inline">\(\frac{p_1}{1-p_0}=0.313035\)</span></td>
<td align="center"><span class="math inline">\(\frac{1-p_0^M}{1-p_0}~p_1=0.125214\)</span></td>
</tr>
<tr class="odd">
<td align="center">2</td>
<td align="center"><span class="math inline">\(p_2=p_1\left( \frac{\lambda}{2}\right)=0.27067\)</span></td>
<td align="center"><span class="math inline">\(p_2^T=p_1^T\left(\frac{\lambda}{2}\right)=0.313035\)</span></td>
<td align="center"><span class="math inline">\(p_2^M=0.125214\)</span></td>
</tr>
<tr class="even">
<td align="center">3</td>
<td align="center"><span class="math inline">\(p_3=p_2\left(\frac{\lambda}{3}\right)=0.180447\)</span></td>
<td align="center"><span class="math inline">\(p_3^T=p_2^T\left(\frac{\lambda}{3}\right)=0.208690\)</span></td>
<td align="center"><span class="math inline">\(p_3^M=p_2^M\left(\frac{\lambda}{2}\right)=0.083476\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="modified-poisson-exercise" class="section level4">
<h4><span class="header-section-number">2.5.1.3</span> Modified Poisson Exercise</h4>
<p><em>Exercise: Course 3, May 2000, Exercise 37.</em> You are given:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(p_k\)</span> denotes the probability that the number of claims equals <span class="math inline">\(k\)</span> for <span class="math inline">\(k=0,1,2,\ldots\)</span></p></li>
<li><p><span class="math inline">\(\frac{p_n}{p_m}=\frac{m!}{n!}, m\ge 0, n\ge 0\)</span></p></li>
</ol>
<p>Using the corresponding zero-modified claim count distribution with <span class="math inline">\(p_0^M=0.1\)</span>, calculate <span class="math inline">\(p_1^M\)</span>.</p>
</div>
</div>
</div>
<div id="mixture-distributions" class="section level2">
<h2><span class="header-section-number">2.6</span> Mixture Distributions</h2>
<div id="mixtures-of-finite-populations" class="section level3">
<h3><span class="header-section-number">2.6.1</span> Mixtures of Finite Populations</h3>
<ul>
<li><p>Suppose that our population consists of several subgroups, each having their own distribution</p></li>
<li><p>We randomly draw an observation from the population, without knowing which subgroup that we are drawing from</p></li>
<li><p>For example, suppose that <span class="math inline">\(N_1\)</span> represents claims form “good” drivers and <span class="math inline">\(N_2\)</span> represents claims from “bad” drivers. We draw <span class="math display">\[N =
\begin{cases}
N_1  &amp;  \text{with prob~}\alpha\\
N_2  &amp;   \text{with prob~}(1-\alpha) .\\
\end{cases}\]</span></p></li>
<li><p>Here, <span class="math inline">\(\alpha\)</span> represents the probability of drawing a “good” driver.</p></li>
<li><p>Our is said to be a “mixture” of two subgroups</p></li>
</ul>
<div id="finite-population-mixture-example" class="section level4">
<h4><span class="header-section-number">2.6.1.1</span> Finite Population Mixture Example</h4>
<p><em>Exercise. Exam “C” 170</em>. In a certain town the number of common colds an individual will get in a year follows a Poisson distribution that depends on the individual’s age and smoking status. The distribution of the population and the mean number of colds are as follows:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">Proportion of population</th>
<th align="center">Mean number of colds</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Children</td>
<td align="center">0.3</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td>Adult Non-Smokers</td>
<td align="center">0.6</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td>Adult Smokers</td>
<td align="center">0.1</td>
<td align="center">4</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: decimal">
<li><p>Calculate the probability that a randomly drawn person has 3 common colds in a year.</p></li>
<li><p>Calculate the conditional probability that a person with exactly 3 common colds in a year is an adult smoker.</p></li>
</ol>
</div>
</div>
<div id="mixtures-of-infinitely-many-populations" class="section level3">
<h3><span class="header-section-number">2.6.2</span> Mixtures of Infinitely Many Populations</h3>
<ul>
<li><p>We can extend the mixture idea to an infinite number of populations.</p></li>
<li><p>To illustrate, suppose we have a population of drivers. The <span class="math inline">\(i\)</span>th person has their own (personal) expected number of claims, <span class="math inline">\(\lambda_i\)</span>.</p></li>
<li><p>For some driver’s, <span class="math inline">\(\lambda\)</span> is small (good drivers), for others it is high (not so good drivers). There is a distribution of <span class="math inline">\(\lambda\)</span>.</p></li>
<li><p>A convenient distribution is to use a gamma distribution with parameters <span class="math inline">\((\alpha, \theta)\)</span>.</p></li>
<li><p>Then, one can check that <span class="math display">\[\begin{aligned}
N &amp;\sim&amp; \text{Negative Binomial} (r = \alpha, \beta = \theta) .\end{aligned}\]</span> See, for example, KPW, page 84.</p></li>
<li><p>Mixture is very important in insurance applications, more on this later…</p></li>
</ul>
<div id="negative-binomial-as-a-gamma-mixture-of-poissons---example" class="section level4">
<h4><span class="header-section-number">2.6.2.1</span> Negative Binomial as a Gamma Mixture of Poissons - Example</h4>
<p><em>Example</em>. Suppose that <span class="math inline">\(N|\Lambda \sim\)</span> Poisson<span class="math inline">\((\Lambda)\)</span> and that <span class="math inline">\(\Lambda \sim\)</span> gamma with mean of 1 and variance of 2. Determine the probability that <span class="math inline">\(N=1\)</span>.</p>
<p><em>Solution.</em> For a gamma distribution with parameters <span class="math inline">\((\alpha, \theta)\)</span>, we have that mean is <span class="math inline">\(\alpha \theta\)</span> and the variance is <span class="math inline">\(\alpha \theta^2\)</span>. Thus <span class="math display">\[\begin{aligned}
\alpha &amp;= \frac{1}{2} \text{   and   } \theta =2.\end{aligned}\]</span></p>
<p>Now, one can directly use the negative binomial approach to get <span class="math inline">\(r = \alpha = \frac{1}{2}\)</span> and <span class="math inline">\(\beta= \theta =2\)</span>. Thus <span class="math display">\[\begin{aligned}
\Pr(N=1) = p_1  &amp;= {1+r-1 \choose 1}(\frac{1}{(1+\beta)^r})(\frac{\beta}{1+\beta})^1 \\
&amp;=                 {1+\frac{1}{2}-1 \choose 1}{\frac{1}{(1+2)^{1/2}}}(\frac{2}{1+2})^1\\
&amp;=  \frac{1}{3^{3/2}} = 0.19245 .\end{aligned}\]</span></p>
</div>
</div>
</div>
<div id="goodness-of-fit" class="section level2">
<h2><span class="header-section-number">2.7</span> Goodness of Fit</h2>
<div id="example-singapore-automobile-data" class="section level4">
<h4><span class="header-section-number">2.7.0.1</span> Example: Singapore Automobile Data</h4>
<ul>
<li><p>A 1993 portfolio of <span class="math inline">\(n=7,483\)</span> automobile insurance policies from a major insurance company in Singapore.</p></li>
<li><p>The count variable is the number of automobile accidents per policyholder.</p></li>
<li><p>There were on average 0.06989 accidents per person.</p></li>
</ul>
<p><span class="math display">\[
\begin{matrix}
\hline \textbf{Table. Comparison of Observed to Fitted Counts } \\
\textbf{Based on Singapore Automobile Data} \\
\begin{array}{crr}
\hline
\text{Count} &amp; \text{Observed} &amp; \text{Fitted Counts using the} \\
(k) &amp; (m_k) &amp; \text{Poisson Distribution} (n\widehat{p}_k) \\
\hline
0 &amp; 6,996 &amp; 6,977.86 \\
1 &amp; 455 &amp; 487.70 \\
2 &amp; 28 &amp; 17.04 \\
3 &amp; 4 &amp; 0.40 \\
4 &amp; 0 &amp; 0.01 \\ \hline Total &amp; 7,483 &amp; 7,483.00 \\ \hline
\end{array}
\end{matrix}\]</span></p>
<p>The average is <span class="math inline">\(\bar{N} = \frac{0\cdot 6996 + 1 \cdot 455 + 2 \cdot 28 + 3 \cdot 4 + 4 \cdot 0}{7483} = 0.06989\)</span>.</p>
</div>
<div id="singapore-data-adequacy-of-the-poisson-model" class="section level4">
<h4><span class="header-section-number">2.7.0.2</span> Singapore Data: Adequacy of the Poisson Model</h4>
<ul>
<li><p>With the Poisson distribution</p>
<ul>
<li><p>The maximum likelihood estimator of <span class="math inline">\(\lambda\)</span> is <span class="math inline">\(\widehat{\lambda}=\overline{N}\)</span>.</p></li>
<li><p>Estimated probabilities, using <span class="math inline">\(\widehat{\lambda}\)</span>, are denoted as <span class="math inline">\(\widehat{p}_k\)</span>.</p></li>
</ul></li>
<li><p>For goodness of fit, consider <em>Pearson’s chi-square statistic</em> <span class="math display">\[\sum_k\frac{\left( m_k-n\widehat{p}_k \right) ^{2}}{n\widehat{p}_k}.\]</span></p>
<ul>
<li><p>Assuming that the Poisson distribution is a correct model; this statistic has an asymptotic chi-square distribution</p>
<ul>
<li>The degrees of freedom (<span class="math inline">\(df\)</span>) equals the number of cells minus one minus the number of estimated parameters.</li>
</ul></li>
<li><p>For the Singapore data, this is <span class="math inline">\(df=5-1-1=3\)</span>.</p></li>
<li><p>The statistic is 41.98; the basic Poisson model is inadequate.</p></li>
</ul></li>
</ul>
</div>
<div id="example.-course-cexam-4.-may-2001-19." class="section level4">
<h4><span class="header-section-number">2.7.0.3</span> Example. Course C/Exam 4. May 2001, 19.</h4>
<p>During a one-year period, the number of accidents per day was distributed as follows:</p>
<table>
<tbody>
<tr class="odd">
<td align="left">Number of Accidents</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">4</td>
<td align="right">5</td>
<td></td>
</tr>
<tr class="even">
<td align="left">Number of Days</td>
<td align="right">209</td>
<td align="right">111</td>
<td align="right">33</td>
<td align="right">7</td>
<td align="right">5</td>
<td align="right">2</td>
<td></td>
</tr>
</tbody>
</table>
<p>You use a chi-square test to measure the fit of a Poisson distribution with mean 0.60. The minimum expected number of observations in any group should be 5. The maximum number of groups should be used.</p>
<p>Determine the chi-square statistic.</p>
</div>
</div>
<div id="exercises" class="section level2">
<h2><span class="header-section-number">2.8</span> Exercises</h2>
<p>Here are a set of exercises that guide the viewer through some of the theoretical foundations of <strong>Loss Data Analytics</strong>. Each tutorial is based on one or more questions from the professional actuarial examinations – typically the Society of Actuaries Exam C.</p>
<p style="text-align: center;">
<a href="http://www.ssc.wisc.edu/~jfrees/loss-data-analytics/loss-data-analytics-problems/">Frequency Distribution Guided Tutorials</a>
</p>

</div>
</div>
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//lossdataanalytics.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="C-Intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="C-Severity.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/Chapters/FrequencyDist.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
